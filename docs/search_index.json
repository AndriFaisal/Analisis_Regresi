[["index.html", "Analisis Regresi Tentang Buku Cara Menggunakan Buku ini Preview book", " Analisis Regresi Andri Faisal 2024-12-04 Tentang Buku Buku ini berisi mengenai masalah regresi yakni mencari hubungan anatara beberapa variabel terhadap variabel lainnya. Cara Menggunakan Buku ini Buku ini berisikan teori dari Regresi dan penggunaan dalam penelitian. Ada latihan dalam penggunaan buku ini. Preview book Buku ini mudah-mudahan dapat menambah khasanah ilmu statistik terutama dalam pengelolaan dengan Rstudio "],["assalamu-alaikum-pembaca.html", "Assalamu ’alaikum Pembaca Sekapur Sirih", " Assalamu ’alaikum Pembaca Buku ini berisi materi mengenai Regresi dan mencoba untuk memberikan pengertian mengenai regresi itu sendiri konsep dan filsofinya. ada Berbagai regresi yang bisa digunakan sesuai dengan kebutuhan dari penelitian dan ketresediaan data yang ada. Sekapur Sirih Bagian Buku ini terdiri dari teori dan ada dalam bagian belakang adalah kita untuk membuat sesuatu pekerjaan mengenai pembuatan dalam RStudio Kita memghadapai dunia yang mempunyai banyak sekali data yang ada. Sleuruh data ini berguna untuk kehidupan kita. maka data-data tersebut kita bisa pegrunakan untuk beberapa hal seperti menganaliss pola dari data tersebut, memprediksi mulai serta mempertimbangakan data untuk pengambilan keputusan. Materi ini adala materi yang ringkas dan juag mengambil dari para ahli sebagai referensi. Mengumpulkan sebanyak-banyaknya dari para ahli yang ada sehingga bisa memberikan pengertian mengenai filsafat dari ilmu statistik. Dari awal kami memberikan suatau pengertian mengenai persiapan untuk analisis data dengan kemudian kita akan bisa mebuat data dari spreadhseet. kemudian steleah itu kita bisa analisis data tersebut sehingga akan menghasilkan suatu perhitungan nilai dan akan bisa kita analisis lebih jauh lagi. Penulis menyadari banyak sekali kekurangan dalam penulisan itu dan terbuka untuk kritik dan saran para pembaca yang mulia. kritik dan saran dapat dialamatkan ke email andrifaisalram@gmail.com. Sertakan Subjek pada email kritik dan saran. Jakarta "],["pendahuluan.html", "Chapter 1 Pendahuluan", " Chapter 1 Pendahuluan You can add parts to organize one or more book chapters together. Parts can be inserted at the top of an .Rmd file, before the first-level chapter heading in that same file. Add a numbered part: # (PART) Act one {-} (followed by # A chapter) Add an unnumbered part: # (PART\\*) Act one {-} (followed by # A chapter) Add an appendix as a special kind of un-numbered part: # (APPENDIX) Other stuff {-} (followed by # A chapter). Chapters in an appendix are prepended with letters instead of numbers. Saya juga mencoba yang namanya tabel dari sini saya akan lihat di mtcars di 1.1 knitr::kable( head(mtcars, 10), caption = &#39;Here is a nice table 2!&#39;, booktabs = TRUE ) Table 1.1: Here is a nice table 2! mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 Saya mau menampilkan tabel tanda menaruh kode chunk tabel ada di lihat di 1.2 Table 1.2: Here is a nice table 3! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa "],["regresi-linear-sederhana.html", "Chapter 2 Regresi Linear Sederhana 2.1 Grafik Pencar atau Scatter Graph Keterbatasan Regresi Linear Perbedaan nilai R2 dengan koefisien Korelasi", " Chapter 2 Regresi Linear Sederhana 2.1 Grafik Pencar atau Scatter Graph Salah satu hal yang penting adalah ketika kita mau menduga hubungan antara variabel X dengan variabel Y yakni dengan scatter graph. Dengan gambar yang ada hubungan. Variabel Y akan kita tempatkan di bagian vertikal atau bagian yang menhadap ke atas sebaliknya dengan bagian X yang mendatar seperti horizontal. adapun mengenai scatter diagram saya akan membuat dengan yang namanya data dari mtcars yang berasal dari Rstudio. dalam hal ini saya akan mengunakan Horsepower dan mil peragalon atau mpg2.1 plot(mtcars$hp, mtcars$mpg, main = &quot;Scatter Plot of Horsepower vs MPG&quot;, xlab = &quot;Horsepower&quot;, ylab = &quot;Miles per Gallon&quot;, col = &quot;blue&quot;, pch = 19) # Bentuk titik Figure 2.1: Diagram Scatter! Kita memasangkan sesuai dengan pasangan nilai data tersebut X dan Y. Jangan pasang teracak agar kita bisa melihat hubungan antara keduanya. Pasangan data tersebut adalah yang termasuk dalam individu misalnya ada seorang yang mempunyai pendapatan X dengan pengeluaran Y maka nilai itu yang kita pasangkan bukan malah membuat pendapatan seorang tertentu dengan pengeluaran yang lain karena itu akan menjadi berbeda nilainya. Dari hubungan tersebut akan membentuk scatter graph. Ada sejumlah titik-titik yang menyebar atau mengumpul di sekitar grafik pencar scatter graph tersebut. Titik titik itu mewakili banyak individu yang memiliki nilai dari kedua variabel X dan Y. Banyaknya kumpulan titik atau scatter itu bergantung dari banyaknya daat tersebut. Semakin banyak jumlah data yang dibuat sampel adalah dengan dimasukkan dalam grafik tersebut. Ada beberapa hal yang dapat kita pelajari dari scatter plot seperti: 1. Pola dari titik tersebut mempunyai pola seperti cenderung mengumpul di satu tempat karena nilanya mempunyai yang sama 2. Trend. Kita dapat melihat suatu trend ketika ada satu garis yang bisa kita tarik pada titik tersebut dan kita menunjukkan ada yang bisa menunjukan garis ke atas atau bahkan tidak memiliki trend. 3. Outlier. Outlier adalah nilai yang terpencil . Ia hanya sendiri dan jauh di pinggir atau ditengah nilai-nilai yang lain karenanya disebut outlier. Outlier tentu sedikit dan ini menyebabkan data tidak normal. Regresi Linear adalah salah satu cara untuk melihat hubungan antara variabel bebas dengan variabel tidak bebas. Dalam hal ini yang mempengaruhi adalah variabel yang bebas sedangkan yang dipengaruhi adalah variabel tidak bebas. Dalam regresi hanya mengenal satu arah saja pengaruh yakni variabel bebas terhadap variabel dependen dan bukan sebaliknya. Pembatasan itu dengan tegas agar dalam mencari hubungan tidak akan ada kekeliruan. Misalnya pengaruh garam terhadap darah tinggi maka dari sini kita akan mencari hubungan antara garam dengan darah tinggi. Garamlah yang mempengaruhi tingginya tekanan darah (tensi) seseorang. Dengan alasan ilmiah dan penjelasan kalau zat garam akan meningkatkan tekanan darah tersebut. Kita tentu tidak akan menempatkan garam sebagai hal yang dependen tetapi ia adalah sesuatau yang bebas dalam hal ini karenanya ia mempengaruhi tekanan darah tinggi. Apakah ia akan menjadi faktor yang dipengaruhi . Hal itu bisa saja kalau dalam konteks yang lain misalnya kalau garam itu akan dipengaruhi oleh jumlah sinar matahari yang menerpa bumi. Regresi linear pertama kali dikenalkan oleh Galton Galton (1886) yang menemukan adanya hubungan tinggi anak dengan tinggi orang tuanya. Ia menghitung jumlah banyaknya anak yang mempunyai dengan tinggi orang tuanya. Hal ini berkaiatan dengann keturunan atau hereditas. Galton ingin menemukan apakah ada tinggi orang tua akan mempengaruhi tinggi sang anak. Regresi linear hanya memeriksa antara hubungan variabel beas dengan variabel tidak bebas. Dalam regresi ini karena hanya ada satu maka disebut juga regresi linier sederhana (simple linear regression). Metode seperti ini dipakai seperti di ilmu bisnis, ekonomi, manajemen, komunikasi dan ilmu sosial lainnya. Dalam regresi sederhana kita akan menggambarkan hubungan dengan garis y= a+ bx. (2.1) \\[\\begin{equation} Y = a + bX \\tag{2.1} \\end{equation}\\] Persamaan ini dihasilkan dari perhitungan regresi terhadap dua variabel tersbeut. Untuk nilai b diperoleh dengan perhitungan jelaskan dulu mengenai perhitungan ada simpangan x dengan simpangan y dibagi dengan jumlah sample atau n. maka bisa dilihat seperti ini. Kemudian nilai a diperoleh dari nilai y rata-rata dikurangi b dikalikan dengan nilai rata-rata X dan akan kita peroleh nilai a tersebut. Bisa saja dengan menggunakan nilai perhitungan komputasi seperti Excel atau menggunakan software statistic lainnya. Dimana a = nilai intercept atau nilai konstanta b = koefisen slope atau kemiringan Nilai a adalah konstanta ini adalah nilai awal dari persamaan suatu garis persamaan regresi tersebut. Nilai ini selalu ada. Hal yang ketika terjadi nilai regresor tersebut nol maka tetap saja nilai untuk Y prediksi tetap ada. Inilah nilai yang dinamakan nilai konstanta. Terkadang nama konstanta atau alpha disebut juga intercept sedangkan Beta dinamakan juga slope parameter atau ada juga yang menamakannya parameter. Y (x=0) = a + bx Y = a + 0.x = a Nilai b ini menunjukkan kemiringan dari garis yang menunjukan hubungan antara y dengan X nilai positif berarti nilai yang menunjukkan seiringan atau hubungan yang sama-sama naik atau sama-sama turun. Ketika variabel independen mempunyai nilai yang positif maka akan merubah juga variabel dependen juga akan turut berubah menjadi positif. Bagaimana kalau nilai alpha menjadi 0 maka nilai persamaan tersebut akan memotong garis x karena tidak ada nilai alphanya. Pengaruh nilai independen bergantung dengan koefisein semakin besar maka satau perubahan akan menjadi lebih besar dengan kemiringan yang curam sekali. Misalnya Y = 0,1 + 10 X berarti pengganda dari nilai regresi tersebut akan semakin besar dengan nilai tersebut. Jika nilai kurang dari 1 namun masih nilai positif maka kemiringan tetap ke sebelah kanan jadi nilai X meningkat namun dengan peningkatan nilai tersebut semain kecil bukan besar. Untuk nilai yang negatif menunjukkan nilai tersebut adalah saling bertolak belakang. Ketika variabel independen bergerak naik maka yang terjadi adalah variabel dependen akan menurun dan sebaliknya. Hubungan yang negatif berarti juga saling bertolak belakang dan penambahan variabel independen akan mengurangi variabel dependen tersebut. Keterbatasan Regresi Linear Metode regresi linear adalah metode yang mendapatkan cara untuk menyelidiki hubungan antara variabel dependen dengan variabel independen . Dengan regresi tersebut kita akan mendapatkan nilai korelasi dari persamaan tersebut. Dari dua data yang disamakan tersebut kita akan mendapatkan suatu persamaan r yang mempunyai nilai -1≤r≤1 dengan perincian terhadap berikut. Perbedaan nilai R2 dengan koefisien Korelasi Kalau koefisien menyebutkan nilai koefisen menunjukkan banyaknya atau kuatnya nilai regresi tapi hati-hati kalau hal tersebut adalah berhubungan dengan nilai r dengan nilai koefisen regresi. Baik r dan beta adalah koefisien kalau beta adalah koefisien regresi sedangkan nilai r adalah koefisein korelasi. Koefisien regresi adalah menunjukkan besarnya hubungan ada suatu hubungan yang menjadi pengganda (multiplier). Koefisien regresi juga menjadi unsur dalam persamaan regresi. Hubungan ini menunjukkan akan ada besarnya pengali saja. Sedangkan koefisen korelasi adalah nilai yang menunjukkan adanya seberapa erat hubungan tersebut. Nilai koefisein regresi menaksir atau meramal nilai Y terhadap nilai X, sedangkan kalau untuk nilai R tersebut memperkirakan keeratan hubungan. Apakah nilai tersebut mempunyai keeratan dari nilai r tersebut. Nilai dalam korelasi r dapat disimpulkan apakah ada hubungan yang kuat atau sama sekali tidak ada hubungan dalam kedua variabel tersebut. Sedangkan untuk nilai koefisein regresi maka kita akan melihat lebih jauh lagi untuk mengintrepretasikan nilai tersebut. Kita dapat menyimpulkan karena nilai dari data mentah antara variabel X dengan Y sudah berbeda. Karena nilai X dan Y mempunyai perbedaan yang besar sehingga nilai koefisiennya menjadi besar. Setiap pengaruh nilai satu independent maka akan berdampak besarnya sesuai dengan koefisen yang Ketebatasan Sebagai model awal yang menunjukkan hubungan anatara variabel indpenden dan variable dependen ilmu ini adalah atau metode yang memberikan suatau pengetahunan dalam mencari hubungan tersebut. Ada beberapa variabel yang sebelumnya belum diketahui ddan mungkin hanya estimasi tersbeut. Perhitungan tersebut menghasilkan suatu hubungan yang merata ataupun hubungan seberapa besar pengaruh atau pengganda tersebut dalam koefisien regresi. References "],["regresi-linier-berganda.html", "Chapter 3 Regresi Linier Berganda", " Chapter 3 Regresi Linier Berganda Suatu faktor bukan dipengaruhi satu faktor saja. Seorang yang sukses bukan berasal dari ayah atau ibu yang sukses saja karena ada faktor lain. Ada anak orang kaya yang menjadi miskin karena tidak bisa mengelola harta ayahnya saja. Pada anak yang miskin ia bisa mendapatkan pendidikan dan ia meraih kekayaan yang melimpah karena keahliannya. Dalam praktik regresi linier sederhana sulit sekali dipraktekkan dan pencarian nilai tersebut hanya sederhana untuk mencari faktor yang dapat mempengaruhi faktor independen lainnya. Adanya regresi berganda karena keterbatasan regresi linear itu maksudnya yang sederhana karena tidak mungkin bahwa hal yang mempengaruhi tersebut hanya satu faktor. Sangat sederhana kalau suatu peubah dipengaruhi oleh beberapa peubah yang lainnya. Regresi berganda lebih sulit daripada regresi linier sederhana Ryan (2013) Kita bisa melihat kalau nilai r square itu begitu rendah sekali karena pengaruhnya sedikit sekali. Maka kita harus mencari peubah lain yang akan mempengaruhi juga dan akan meningkatkan nilai R kuadrat. Memang tidak ada jaminan kalau peningkatan variabel atau peubah akan membuat nilai R squared akan meningkat terus. Dalam ilmu pengetahuan kita selalu mengeksplorasi dengan factor-faktor yang lain agar bisa mencari yang paling berpengaruh. Terkadang memang faktor yang diduga tidak berpengaruh maka ternyata membuatnya berpengaruh, Memang dalam regresi kita tidak tahu mana faktor yang paling yang paling berpengaruh tersebut. Sampai saat ini belum ada ukuran yang jelas mengenai hal tersebiut kalu dalam penggunaan yang sama. Namun dalam penggunaan determinasi yang satu mungkin akan terlihat mana faktor yang berpengaruh. Tetapi kalau sudah tercampur terkadang sulit juga karena bias, jadi pengaruh tersebut akan berbeda? Kita bisa melihat di persamaan seperti ini (3.1) \\[\\begin{equation} y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_k x_k + \\epsilon \\tag{3.1} \\end{equation}\\] di mana: - \\(y\\): Variabel dependen. \\(\\beta_0\\): Intersep (konstanta). \\(\\beta_1, \\beta_2, \\ldots, \\beta_k\\): Koefisien regresi. \\(x_1, x_2, \\ldots, x_k\\): Variabel independen. \\(\\epsilon\\): Error (kesalahan residual). References "],["persiapan-data.html", "Chapter 4 Persiapan Data Paket yang dibutuhkan 4.1 Goodnes of fit 4.2 Regresi berganda menggunakan data rstudio Istilah 4.3 Regresi dengan menggunakan Data Panel Soal", " Chapter 4 Persiapan Data Sebelum Melangkah ke analisis data regresi kita menggunakan atau mengolah data terlebih dahulu. Kita mengolah data dengan data frame. Lebih baik kita menaruh data di spreadsheet. Maka sebelumnya adalah kalau kita mau upload file excel maka kita pastikan bahwa kita mempunyai package read excel maka kalau belum kita install dulu dengan read excel dengan perintah install packages (readxl) setelah itu memastikan dengan library (readxl) Setelah itu kita pastikan dengan seperti ini # Contoh membaca file Excel di R library(readxl) # Jalur file contoh (diperbarui sesuai kebutuhan Anda) data &lt;- read_excel(&quot;path/to/file.xlsx&quot;) # Tampilkan beberapa baris pertama data head(data) Pastikan kita menemukan path filenya yang benar ke file yang telah kita tentukan sebelumnya. kemudian kita atur input sheetnya kalau file excel tersebut mempunyai banyak sheetnya. Kalau satu biasanya akan diarahkan ke sana. setelah itu kita akan memilih variabel dengan memilih kolom yang sesuai dengan variabel yang hendak kita uji. Setelah itu kita bisa menggunakan data set dalam analisis regresi. kalau kita mempunyai package tidy verse maka kita akan mempunyai struktur data yang namanya tibble kalau tidak kita akan mendapatkan data yang namahya data frame. $$ \\[\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\] = \\[\\begin{bmatrix} 1 &amp; x_{11} &amp; x_{12} \\\\ 1 &amp; x_{21} &amp; x_{22} \\\\ \\vdots &amp; \\vdots &amp; \\vdots \\\\ 1 &amp; x_{n1} &amp; x_{n2} \\end{bmatrix} \\begin{bmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_n \\end{bmatrix}\\] \\[\\begin{bmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\epsilon_n \\end{bmatrix}\\] $$ Dari matriks kita bisa melihat peramalan dalam meregresi nilai X atau beberapa variabel independen. Kita lihat perhitungannya sampai sudah rumit apalagi dengan banyak sekali variabel yang ada. Kalau regresi dua faktor hanya ada dua dimensi maka akan ada banyak dimensi. Dimensi ini akan mampu menjelaskan hubungan dari variable independent dan juga variable dependen. Adapun tujuan dari regresi adalah mencari garis persamaan yang dapat digunakan untuk meramal nilai prediksi Y atau variabel independennya sama seperti yang terjadi pada suatu masa. Terkadang data tersebut akan dapat berguna bagi banyak hal sebagai bentuk untuk menilai kebijakan yang akan diterapkan baik oleh organisasi besar dan kecil maupun juga individual yang akan menentukan kebijakan tersebut. Metode regresi linier mempunyai arti adalah untuk mencari hubungan satu variabel tidak bebas atau dependen terhadap beberapa variabel bebas lainnya. Sama halnya regresi sederhana, dalam regresi linier berganda kita akan menguji apakah beberapa variabel bebas akan dapat mempengaruhi dari variabel tidak bebas tersebut. Hasil dari regresi adalah persamaan regresi yang terdiri dari nilai Y terhadap nilai X dengan nilai koefisien seperti nilai variabel satu, variabel dua, dan selanjutnya. Nama dari hasil ini disebut juga persamaan regresi dan juga namanya adalah model regresi. Jika sudah mempunyai masalah dan ingin mengeksplore variabel atau peubah apa saja yang dapat digunakan untuk regresi maka kita dapat melakukan hal seperti ini. Anda harus tahu bahwa variabel yang akan anda cari adalah variabel yang benar-benar berpengaruh. Kalau variabel asal kita sambungkan saja maka kita tidak akan mendapatkan hal yang seperti harapan kita. Kita mengharapkan akan mendapatkan sesuatu yang baik. Hal pertama yang kita bisa lakukan adalah mengumpulkan data yang sesuai dengan tujuan penelitian atau variabel yang kita selidiki. Semuanya harus terkumpul. Semua yang akan dapat kita olah ke dalam regresi tersebut. Penting untuk menata data tersebut dan mengorganisasikan data tersebut. Sebelumnya kita lihat terlebih dulu di tabel apakah ada data outlier. Mungkin agak sulit sekali kalau kita mengandalkan tabel untuk mencari outlier. Setelah itu kita mengeksplorasi data analisis. Sebelum regresi ini bisa dilakukan bagi yang berpengalaman dari grafik akan dapat menduga apakah semua ini akan menjadi nilai estimasi yang baik atau tidak? Justru awal ini adalah mendeteksi ada kemungkinan kita akan melihat adanya hal yang tidak sesuai dengan data yang hendak kita regresi. Setelah itu kita bisa melihat adanya outliers. Data di grafik tersebut maka kita akan melihat adanya outlier yang ada. Penting mempertimbangkan adanya outlier ini. Outlier adalah salah satu nilai yang berbeda dari kebanyakan rata-rata. Nilai dari outlier dapat membuat hasil dari model regresi bias. Kita harus memastikan data yang kita dapatkan adalah data yang obyektif dan memenuhi syarat. Terkadang kita mengumpulkan data yang salah. Apalagi sampai menggunakan data yang salah ini menjadi permasalahan tersendiri. Setelah itu lakukan regresi untuk menghitung atau mengkalkulasi nilai dari persamaan regresi tersebut. Kita akan mendapatkan nilai R kuadrat atau yang dikenal dengan R Square tersebut. Nilai R2 akan mencapai sekitar 100% namun kemungkinan itu tidak ada karena kalau ada yang 100% maka patut kita curigai. Kemudian kita akan mencari nilai F tersebut yang sudah dihitung. Nilai ini adalah nilai signifikasi dari model yang kita buat. Setelah itu kita bisa untuk menilai dari variabel yang sesuai dengan nilai signifikasi. Tidak semua yang akan ada akan ada maka akan membuat semuanya signifikan karena ada saja yang hasilmya berbeda sesuai dengan data yang ada. Terakhir kita harus melihat juga asumsi model. Kita akan memastikan nilai dari persamaan regresi sudah “benar”. Hasil regresi itu tidak bisa dikatakan benar atau salah karena semuanya ada perhitungannya. Dalam buku ini selain untuk menggunakan data dari penulis kita juga menggunakan dataset yang ada di Rstudio. Kalau anda mempunyai perangkat maka ada beberapa datasets yang bisa digunakan seperti Chickweights, trees, mtcars, dan lain-lain. Dataset ini sudah rapih tinggal kita bisa menggunakan dalam bentuk beberapa seperti visualisasi, analisis deskriptif, maupun analisis regresi. Paket yang dibutuhkan Dalam analisis regresi kita bisa membutuhkan paket dalam perangkat lunak (software) Statistik Rstudio ini adalah untuk melakukan beberapa regresi seperti halnya: lmtest ; paket ini yang sering digunakan karena memmuat beberapa fungsi seperti lm dan juga glm pada fungsi ini juga memuat bptest dan dwtest car : Paket ini digunakan untuk beberapa fungsi seperti uji durbin watson, multikolinearitas, dan scatterplot matrix. ggplot2 : paket ini untuk membuat visualisasi data atau pembuatan grafik Ada banyak sekali package namun tiga paket diatas juga sudah cukup untuk membuat analisis regresi. Banyak sekali package yang ada dan akan selalu berkembang menurut apa yang akan ada dalam Rstudio tersebut. 4.1 Goodnes of fit Untuk mendapatkan nilai yang paling baik adalah hal yang diinginkan. Tentu tidak memaksakan sesuatu hal yang akan menjadikan sesuatunya tidak benar atau tidak shahih dan valid. Kita dapat memeriksa nilai dari residu yang merupakan nilai Y aktual dengan Y prediksi atau sering disebut Y topi. Nilai ini merupakan nilai dari total semua residu. Sedangkan di sisi lain adalah kita menilai nilai Y dengan nilai y rata-rata dari variabel Y tersebut yang bisa jadi akan nilainya besar. Kemudian kita juga memperlihatkan nilai selisih antara Variabel Y dengan regresi dalam nilai tersebut nilai SST yang besar sangat diharapkan menandakan nilai yang baik juga. Kemudian ada juga Nilai SSE atau nilai Sum Square Explained adalah nilai yang paling diharapkan tinggi. Ini adalah selisih nilai y aktual dengan nilai y rata-rata. Sedangkan nilai dari SSR adalah sum square dari residual dan nilai ini adalah nilai y prediksi dengan y aktual. Sum Square Total = SST = SSR + SSE Dari nilai ini kita akan memperoleh nilai R squared atau R kuadrat yang rumusnya adalah SSE/SST. Oleh karena itu yang diharapkan adalah nilai R2 besar sekali. Karena semakin nilai itu besar sekali akan menunjukkan bahwa ada hubungan yang mempunyai poris besar sekali. Kita juga harus bisa membandingkan dengan nilai adjusted R square yang membandingkan dengan berbagai variabel atau variabel yang lebih dari satu. Cara Adjusted R square ini adalah cara yang lebih konservatif dalam menjelaskan kesesuaian (fit) model. Adapun rumus dari adjusted R Square adalah sebagai berikut ini: Adjusted R2 = 1-[(1-R2)*(n-1)/(n-p-1)] Nilai ini adalah jumlah obesravsi atau jumlah data yang dilibatkan dalam regresi. Dengan demikian nilai R square adjusted itu lebih digunakan pada waktu regresi terhadapa variable ini lebih dari dua variable bebas. Hal ini ada seperti penyesuaian dengan niai R2 tersebut. Nilai yang paling penting adalah nilai F. Nilai yang diperoleh dari nilai ANOVA ini menunjukkan kesesuaian model (fit of model). Kalau nilai dari F signifikan ini lebih kecil dari 0,05 dalam nilai ini adalah nilai yang baik. Kalau sebaliknya nilai peluang (probability value) adalah lebih besar maka tidak diterima model tersebut. Ada yang menjadi masalah dalam model tersebut. Itu yang dapat kita ketahui. Kalau model tersebut mungkin kita pikirkan model yang lain yang dapat kita jadikan model yang baru tersebut. Setelah yakin bahwa model tersebut sah kita melihat beberapa variable independent yang diduga mempengaruhi variable dependen tersebut. Kita melihat nilai t yang ada pada bagian setiap variable yang ada. Kalau nilai t hitung dalam hal ini t hitung yang dikalkulasi oleh software. Nilai t itu mempunyai nilai mutlak yang lebih besar daripada nilai table IthitungI &gt; IttabelI. Nilai dalam kurung menunjukan nilai mutlak dari t. Ketika nilai t hitung positif maka nilai yang paling besar juga akan menjadi niai yang paling besar. Kalau nilai negatf maka nilai tersebut nilai yang paling besar. Sejatinya nilai minus yang paling besar adalah nilai yang kecil namun karena masuk dalam nilai mutlak maka nilai minus yang besar menjadi nilai yang paling besar. Masalah penerimaan ini juga bergantung dengan uji nilai yang untuk ditetapkan. Ada uji yang dua arah dan ada juga uji satu arah bergantung dengan kebutuhan yang dibutuhkan oleh regresi tersebut. Adapun daerah penolakan tersebut terkait dengan dua arah, Jika berada dalam jangkauan t table maka kita dapat menolak hipotesis yang menyatakan bahwa ada pengaruh pada variable tersebut. 4.2 Regresi berganda menggunakan data rstudio Pada bagian ini saya akan menggunakan data RStudio untuk mendapatkan mengenai rstudio dengan menggunakan dataset yang sudah ada di RStudio yakni dataset yang namanya mtcars. Data mtcars mempunyai beberapa variabel namun sebagai contoh hanya meregresi dua variabel independen saja yakni cyl + disp dengan variabel dependennya adalah mpg atau mile per galon data(mtcars) regresimtcars1&lt;-lm(mpg~cyl+disp,data=mtcars) summary(regresimtcars1) ## ## Call: ## lm(formula = mpg ~ cyl + disp, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.4213 -2.1722 -0.6362 1.1899 7.0516 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 34.66099 2.54700 13.609 4.02e-14 *** ## cyl -1.58728 0.71184 -2.230 0.0337 * ## disp -0.02058 0.01026 -2.007 0.0542 . ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.055 on 29 degrees of freedom ## Multiple R-squared: 0.7596, Adjusted R-squared: 0.743 ## F-statistic: 45.81 on 2 and 29 DF, p-value: 1.058e-09 Istilah Korelasi : Hubungan anatara suatau variable dengan suatu variable Regresi : Metode Statistik untuk mencari hubungan antara peubah bebas terhadap peubah tidak bebas Model regresi : model prediksi yang merupakan hasil regresi Outlier : data yang nilainya berbeda dari banyak data umumnya atau rata-ratanya. R kuadrat (R^2) : Nilai yang menunjukkan porsi pengaruh variable independent terhadap variable dependen Adjusted R square : Nilai R kuadrat yang sudah di sesuaikan Goodness of fit : Dalam Bahasa Indonesia keseuaian model ini menunjukkan model dari regresi yang sudah sesuai Scatter Diagram: diagram pencar adalah titik yang menghubungkan antara variabel bebas dan varaibel tidak bebas 4.3 Regresi dengan menggunakan Data Panel Mengelola data panel di RStudio untuk mengestimasi persamaan regresi dan mencari pengaruh variable independent terhadapa variable dependen. Salah satu metode untuk mencari pengarih variable adalah dengan data panel. Pengaruh seperti ini adalah untuk kita dapat mengestimasi daripada variable dependen. Data panel adalah data kumpulan dalam bentuk 4.3.1 Membuat Struktur Data Panel Rstudio berbeda dari perangkat lunak (software) statistik lainnya. Untuk mengelola dalam analisis appaun membutuhkan struktur data dalam bentuk rstudio. Kalau software lain cukup menyalin dan menempel (copy and paste) data spreadsheet baik itu Excel atau Google Spreadsheet dan langsung dapat untuk mengelola data namun untuk RStuido harus merubahkan dalam bentuk model data yang dikenal oleh Rstudio. Langkahnya adalah mengimpor file speadhheet dan membuat ebberapa pengaturan yang relative mudah untuk membuat data anda mudah diolah. Khusus untuk analisis panel maka yang dibutuhkan bentuk data atau struktur dari data pdata.frame yang merupakan singkatan panel data frame. Ini berbeda dengan data frame biasa di rtsuido karena ini mempertimbangkan dimensi individual dan juga dimensi waktu. Perlakukan inilah yang membuat berbeda. Disebelak kana anda dapat mengklik import data set dan pilihlah excel. Ada beberapa pilihan lain seperti spss sas, stata, text dan lain-lain. KAlau mempunyai speadsheet maka pilihlah excel. Setelah itu anda akan mmeilih beberapa sheet. Kalau anda bekerja dalam banyak sheet di satu file maka anda harus memilih salah satu sheet. Dibawah itu anda pilih. Maka anda harus meperhatikan kerapihan dari text yang anda buat. Misalnya ada sela diantara judul table dan juga isi data maka di table yang kosong itu akan tertulis NA atau Not Available yang berarti data tidak tersedia. Menyiapkan excel sebagai data Untuk menyusun data maka yang bisa kita lakukan adalah dengan data. Karena data dnegan speadhseet kita lebih mudah. Kita bisa menyusun dengan data seperti contoh dibawah ini tobinq &lt;- read.csv2(&quot;~/jurnal/tobinq3.csv&quot;) #setelah data diupload saya akan membuat data frame khusus panel yang disebut pdata frame dengan seperti ini. jangan lupa gunakan library plm library(plm) ## Warning: package &#39;plm&#39; was built under R version 4.3.3 ptobinq=pdata.frame(tobinq,index=c(&quot;Comp&quot;,&quot;Tahun&quot;),drop.index = TRUE,row.names=TRUE) Setelah data sudah benar masuk kita dapat mengecek struktur dari data tersebut str(ptobinq) ## Classes &#39;pdata.frame&#39; and &#39;data.frame&#39;: 40 obs. of 3 variables: ## $ DAR : &#39;pseries&#39; Named num 0.49 0.44 0.42 0.4 0.4 0.49 0.44 0.42 0.4 0.4 ... ## ..- attr(*, &quot;names&quot;)= chr [1:40] &quot;Adaro-2014&quot; &quot;Adaro-2015&quot; &quot;Adaro-2016&quot; &quot;Adaro-2017&quot; ... ## ..- attr(*, &quot;index&quot;)=Classes &#39;pindex&#39; and &#39;data.frame&#39;: 40 obs. of 2 variables: ## .. ..$ Comp : Factor w/ 8 levels &quot;Adaro&quot;,&quot;ATPK&quot;,..: 1 1 1 1 1 2 2 2 2 2 ... ## .. ..$ Tahun: Factor w/ 5 levels &quot;2014&quot;,&quot;2015&quot;,..: 1 2 3 4 5 1 2 3 4 5 ... ## $ DER : &#39;pseries&#39; Named num 0.97 0.78 0.72 0.67 0.66 0.97 0.78 0.72 0.67 0.66 ... ## ..- attr(*, &quot;names&quot;)= chr [1:40] &quot;Adaro-2014&quot; &quot;Adaro-2015&quot; &quot;Adaro-2016&quot; &quot;Adaro-2017&quot; ... ## ..- attr(*, &quot;index&quot;)=Classes &#39;pindex&#39; and &#39;data.frame&#39;: 40 obs. of 2 variables: ## .. ..$ Comp : Factor w/ 8 levels &quot;Adaro&quot;,&quot;ATPK&quot;,..: 1 1 1 1 1 2 2 2 2 2 ... ## .. ..$ Tahun: Factor w/ 5 levels &quot;2014&quot;,&quot;2015&quot;,..: 1 2 3 4 5 1 2 3 4 5 ... ## $ Tobin.Q: &#39;pseries&#39; Named num -0.2702 0.2346 0.2706 0.034 0.0336 ... ## ..- attr(*, &quot;names&quot;)= chr [1:40] &quot;Adaro-2014&quot; &quot;Adaro-2015&quot; &quot;Adaro-2016&quot; &quot;Adaro-2017&quot; ... ## ..- attr(*, &quot;index&quot;)=Classes &#39;pindex&#39; and &#39;data.frame&#39;: 40 obs. of 2 variables: ## .. ..$ Comp : Factor w/ 8 levels &quot;Adaro&quot;,&quot;ATPK&quot;,..: 1 1 1 1 1 2 2 2 2 2 ... ## .. ..$ Tahun: Factor w/ 5 levels &quot;2014&quot;,&quot;2015&quot;,..: 1 2 3 4 5 1 2 3 4 5 ... ## - attr(*, &quot;index&quot;)=Classes &#39;pindex&#39; and &#39;data.frame&#39;: 40 obs. of 2 variables: ## ..$ Comp : Factor w/ 8 levels &quot;Adaro&quot;,&quot;ATPK&quot;,..: 1 1 1 1 1 2 2 2 2 2 ... ## ..$ Tahun: Factor w/ 5 levels &quot;2014&quot;,&quot;2015&quot;,..: 1 2 3 4 5 1 2 3 4 5 ... Sudah benar maka langkahnya adlah mennetukan jenis regresi data panel yang akan kita lakukan. Kemudian sesuai langkah yang sudah kita rencanakan adalah awalnya dengan melakukan regresi dari ketiga metode seperti Pooling (pooling), Fixed Effect (within) dan Random. Dalam contoh kali ini saya akan mennamakan kalau pooling adalah regplmtobinq, untuk fixed effect adalah regplmtobinq2 dan untuk random adalah regplmtobinq3. Dalam tiap perintah aka nada Namanya perintah summary yang artinya adalah menampilkan hasil regresi tersebut. #Regresi Model Pooling regplmtobinq&lt;-plm(Tobin.Q ~ DAR+DER,data=ptobinq,model=&quot;pooling&quot;) summary(regplmtobinq) ## Pooling Model ## ## Call: ## plm(formula = Tobin.Q ~ DAR + DER, data = ptobinq, model = &quot;pooling&quot;) ## ## Balanced Panel: n = 8, T = 5, N = 40 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -1.02749 -0.70659 -0.29490 0.20208 4.38311 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## (Intercept) 1.5134678 0.3209255 4.7159 3.381e-05 *** ## DAR -1.7072093 0.4715372 -3.6205 0.0008754 *** ## DER -0.0038299 0.0682864 -0.0561 0.9555757 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 62.653 ## Residual Sum of Squares: 46.235 ## R-Squared: 0.26204 ## Adj. R-Squared: 0.22215 ## F-statistic: 6.56918 on 2 and 37 DF, p-value: 0.003619 #Regresi Model Fixed regplmtobinq2&lt;-plm(Tobin.Q ~ DAR+DER,data=ptobinq,model=&quot;within&quot;) summary(regplmtobinq2) ## Oneway (individual) effect Within Model ## ## Call: ## plm(formula = Tobin.Q ~ DAR + DER, data = ptobinq, model = &quot;within&quot;) ## ## Balanced Panel: n = 8, T = 5, N = 40 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -1.196028 -0.130457 0.092081 0.186883 1.890241 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## DAR -2.400988 0.589834 -4.0706 0.0003144 *** ## DER -0.087783 0.042093 -2.0854 0.0456365 * ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 17.173 ## Residual Sum of Squares: 11.017 ## R-Squared: 0.35847 ## Adj. R-Squared: 0.16601 ## F-statistic: 8.3817 on 2 and 30 DF, p-value: 0.001283 #Regresi Model Random Effcet regplmtobinq3&lt;-plm(Tobin.Q ~ DAR+DER,data=ptobinq,model=&quot;random&quot;) summary(regplmtobinq3) ## Oneway (individual) effect Random Effect Model ## (Swamy-Arora&#39;s transformation) ## ## Call: ## plm(formula = Tobin.Q ~ DAR + DER, data = ptobinq, model = &quot;random&quot;) ## ## Balanced Panel: n = 8, T = 5, N = 40 ## ## Effects: ## var std.dev share ## idiosyncratic 0.3672 0.6060 0.4 ## individual 0.5506 0.7420 0.6 ## theta: 0.6569 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -0.977977 -0.350254 -0.074708 0.106930 2.785480 ## ## Coefficients: ## Estimate Std. Error z-value Pr(&gt;|z|) ## (Intercept) 1.786432 0.417645 4.2774 1.891e-05 *** ## DAR -2.087653 0.510836 -4.0867 4.375e-05 *** ## DER -0.069591 0.043000 -1.6184 0.1056 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 22.526 ## Residual Sum of Squares: 15.489 ## R-Squared: 0.31236 ## Adj. R-Squared: 0.27519 ## Chisq: 16.8073 on 2 DF, p-value: 0.00022405 ##Latihan {-} B-S Pada regresi berganda yang menjadi variable independent boleh lebih dari satu sedangkan variabel dependen hanya satu saja. B-S Pada regresi variable dependen boeh saja menggunakan variable dummy dan variable gabungan yang lainnya B-S Regresi dapat menunjukkan kekuatan dalam satu variable independent terhadap variable dependen B-S Data outlier adalah data yang berbeda dengan lainnya dan menyebabakan kerusakan dalam regresi. B-S Uji t untuk menunjukkan hubungan yang signifikan variable dependen terhadap variable independent B-S untuk melihat apakah regresi tersebut sudah baik kita dapat melihat nilai Chi Square B-S Autokorelasi bias terjadi dalam regresi linier berganda dan dapat menyebabkan kesalahan B-S Kalau kita menggunakan variabel dummy adalah variable yang digunakan untuk membedakan antara varabel yang mempunyai kategori. B-S Nilai Adjusted R Square selalu lebih besar daripada nilai R Square karena ada tambahan berupa penyesuaian nilai banyaknya variable. Soal Buatlah model dengan cara menilai kesehatan tulang untuk yang segar dengan orang yang sakit sehingga bisa mengembangkan dengan bisa membedakan yang berolahraga ataupun yang tidak? Asumsi apakah yang harus dipenuhi dalam regresi logistik coba jelaskan hal itu? Pada Altman Z Score setidaknya Z Score dibagi menjadi dua dan ada wilayah abu. saya akan gabungkan wilayah abu ke dalam wilayah yang bangkrut. Akankah ini dibenarkan ? Bagaimana cara menjelaskannya? Dalam asumsi ternyata tidak ditemukan maka yang sesuai goodnes of fit atau kebaikan model. Bagaimana mengatasi hal tersebut? Kalau di regresi logit maka iti kita lihat kalau kita melihat ada yang berbeda maka itu seperti variabel dikotomi maka akan bisa melihat misalnya dikotomi dari kesehatan jantung untuk satu dan kesehatan lainnya? Pada suatu hasil regresi ditunjukkan nilai R squarenya adalah 75%. Carilah nilai Adjusted R square model tersebut jika jumlah sample 30 dan variable bebasnya ada tiga? Carilah contoh beberapa variable independent yang mempengaruhi kepuasan pelanggan? Sebutkan beberapa kemungkinan yang ada dari regresi berganda? Apakah semakin banyak variable independent akan meningkatkan nilai R Square. Coba jelaskan jawaban anda? Apakah beda korelasi dengan regresi? "],["asumsi-regresi-linear.html", "Chapter 5 Asumsi Regresi Linear 5.1 Multikolinearitas. 5.2 Autokorelasi 5.3 Heteroskedatisitas 5.4 Asumsi Normalitas", " Chapter 5 Asumsi Regresi Linear Setiap metode yang kita apakah harus kita ingat mempunyau syarat dan kondisi. Seperti kita mau membeli suatu maka kita menemukan suatau kondisi yang harus kita penuhi . Tanpa syarat dan kondisi tersebut maka kita tidak akan mendapatkan apa yang kita maui. Ada beberapa gejala kalau tidak bisa dibilang penyakit yang terdapat pada Regresi linear. Hal tersebut harus kita lewati sebagai syarat nilai peramalan dan juga koefisien determinasi dari regresi tersebut benar-benar valid. Dalam kalkulasi suatu persamaan regresi kita bisa menghasilkan nilai peramalan yang berbeda anatara satu dengan yang lainnya. Bukan salah menghitungnya karena memang sudah sedemikian begitu datanya. Ada beberapa penyebab yang menyebabkan dan biasanya adanya outlier. Bisa jadi kesalahan dalam mengumpulkan data juga turut serta dalam menghasilkan peramalan yang salah. Sudah nilai tersebut salah maka salah karenanya asumsi inilah yang harus diperbaiki. Ada beberapa hal yang membuat regresi tersebut tidak akan menjadi valid yang bisa kita perhatikan seperti ini: 5.1 Multikolinearitas. Kita mau mencari hubungan anatara variabel independen dengan variabel yang dependen, hanya saja terjadi hubungan yang baik antara variabel independen dengan variabel independen juga atau sesama variabel independen. Hubungan ini tidak bisa dibiarkan karena akan menyebabkan variabel tersebut merusak nilai perhitungan dari regresi. Hubungan sesama variabel independen dapat menyebabkan nilai R begitu tinggi, namun penduga (peramalannya menjadi bias). Untuk itu hal ini harus diatasi dengan cara membuang salah satu variabel yang sama. Sebenarnya tidak terlalu sulit untuk menduga akan terjadinya multikolinearitas . Ketika kita melihat ada data tabel yang begitu mirip antara sesama variabel independen, kita harus mengecek apakah kita menyalin data yang sama untuk variabel yang berbeda. Terkadang salah satu data merupakan kelipatan dari data yang lainnya dan inilah yang menyebabkan korelasi begitu tinggi. Pastikan juga tidak ada data yang sama masuk ke dalam variable yang berbeda. Jika yakin ternyata data tersebut juga memang benar maka bisa jadi itu data memang mempunyai sifat yang sama. Hubungan antara korelasi keduanya sangat besar sekali hampir sampai lebih dari 80%. Kalau kita menggunakan Korelasi Pearson maka kita akan mendapatkan nilai korelasi yang tinggi. Kesalahan ini bisa jadi karena memang datanya seperti itu. Seperti harga ayam kampung dengan harga ayam ras maka kita bisa pastikan keduanya mempunyai hubungan yang positif. Kalau harga ayam ras naik maka harga ayam kampung juga naik. Meski keduanya mempunyai harga yang berbeda namun mempunyai peluang untuk naik pada waktu yang sama atau turun pada waktu yang sama. Untuk mendeteksi dari gejala ini adalah dengan melihat nilai VIF yang ada dalam software statistik. Nilai VIF yang lebih besar dari 10 maka terjadi yang namanya multikolinearitas. Kemudian ada juga nilai eugin value yang lebih dari 0,001. Untuk mengatasi multikolinearitas adalah tidak sulit. Hanya saja pilihannya adalah membuang salah satu variable dalam regresi multi variable. Hanya saja masalahnya adalah pilihan yang mana yang mau dibuang kadang ini menjadi pilihan yang dilematis. library(car) ## Warning: package &#39;car&#39; was built under R version 4.3.1 ## Loading required package: carData ## Warning: package &#39;carData&#39; was built under R version ## 4.3.1 library(carData) vif(regresimtcars1) ## cyl disp ## 5.366629 5.366629 HAsil dari regresi tersebut menunjukan tidak terjadinya apa yang namanya multiklineartiast karena nilainya adalah 5,366629 atau masih dibawah nilai VIF=10 5.2 Autokorelasi Nilai Autokorelasi terjadi ketika deret waktu mempunyai nilai galat (error) yang berkorelasi .Hal ini terjadi karena data berseri (time series) yang ada dalam suatu model. Pada beberapa kasus ternyata data cross section sendiri juga dapat mengalami autokorelasi. Pada autokorelasi terjadi karena galat yang berubah menurut waktu. Untuk menilai apakah adanya terjadinya korelasi, kita dapat menggunakan kriteria sebagai berikut yakni dl (Durbin lower) yang berarati nilai Durbin terendah atau du (Durbin upper) yang berarti nilai durbin di atas. Semua nilai yang berada di antara kedua nilai tersebut harus memenuhi syarat sehingga, model yang kita buat sudah dikatakan terbebas dari autokorelasi. Autokorelasi adalah suatu hubungan galat atau error yang berhubungan. Hubungan tersebut akan semakin membesar dan semakin mengecil pada tingkat peramalan yang dibuat oleh model yang memiliki gejala autokorelasi. Mau tidak mau nilai dari autokorelasi harus dihilangkan terlebih dahulu. Dengan kata lain kita harus membuat sesuatu model yang terbebas dari autokorelasi. Apapun regresi yang terjadi kesalahan termasuk autokrelasi karena adanya data tersebut. Karenanya pastikan terlebih dahulu data yang anda kumpulkan tersebut memang sudah benar. Setelah yakin kalau sudah melakukan regresi lagi. Untuk mendeteksi gejala ini kita mengamati pola residual terhadap urutannya atau t. Kalau data residual mempunyai pola tertentu baik meningkat maupun menurun maka patut dicurigai terjadinya autokorelasi. Kalau data tidak mempunyai pola (pattern) atau data tersebar dengan bebas maka tidak terjadi autokorelasi. Selain melakukan uji Durbin Watson kita bisa melakukan uji yang lain seperti Ljung Box uji ini juga dapat untuk menduga regresi yang kita lakukan. Uji ini akan menempatkan H0 atau Hipotesis nol adalah hasil regresi terdapat mengandung autokorelasi sedangkan hipotesis alternatif (Ha) menunjukkan kalau tidak ada autokorelasi dalam model yang diuji. Nilai Durbin Watson yang dikembangkan mempunyai rumus seperti di bawah ini (5.1) \\[\\begin{equation} du= (∑_(t=1)^n(e_(t-1)-e_t )^2 )/(e_t^2 ) \\tag{5.1} \\end{equation}\\] Dengan et = nilai error ke t et-1 = nilai error ke t-1 Dalam uji ini ditetapkan sebagai Hipotesis nol adalah jika terjadi autokorelasi sedangkan Ha diterima jika terjadi autokorelasi H0 : ρ = 0 tidak terjadi autokrelasi Ha : ρ ≠ 0 terjadi autokorelasi Autokorelasi itu terjadi karena danya kandungan data series tetapi seperti disinggung diatas kalau data cross section pun juga menjadi autokorelasi untuk mengatasi adalah kita bisa melakukan hal seperti ini. Kita menggunakan differencing pada data time series. Setelah difference atau pembedaan ada kemungkinan data time series juga bisa diperbaiki. Salah satu mengatasi dengan menggunakan lag. Lag ini adalah konsekuensi dengan nilai dari regresi tersebut. Ada beberapa variable respon tidak selalu merespon dengan cepat. Karenanya ada sebuah respon tersebut maka aka nada repson yang terlambat sekali . Adapun bentuk antisipasi memang semuanya bervariasi karena memang tidak langsung. Bahkan kita curiga kalau suatu reaksi sudah diketahui sebelumnya berarti ada efek antisipasi oleh respon tersebut. Untuk memeriksa apakah adanya autokorelasi maka kita bisa melakukan hal seperti ini yakni menggunakan dwtest yang ada di package lmtest; library(lmtest) ## Warning: package &#39;lmtest&#39; was built under R version ## 4.3.1 ## Loading required package: zoo ## Warning: package &#39;zoo&#39; was built under R version 4.3.1 ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric dwtest(regresimtcars1) ## ## Durbin-Watson test ## ## data: regresimtcars1 ## DW = 1.5965, p-value = 0.09521 ## alternative hypothesis: true autocorrelation is greater than 0 kemudian jalankan dwtets hasilnya menunjukkan nilainya tdiak signifikan berarti menerima hipotesis nol yang menunjukkan tidak terjadinya autokorelasi 5.3 Heteroskedatisitas Pada mengumpulkan data, kita mungkin kurang memperhatikan adanya variance yang berbeda. Seharusnya dalam peramalan regresi juga kita harus memperhatikan asumsi bahwa error tidak berbeda E( ε ) = 0. Adanya perbedaan karena memang sulit sekali bagi regresi linear untuk mencari nilai yang paling mendekati dengan garis persamaan regresi yang mendekati dari data tersebut. Hal ini harus segera dipebaiki. Sebelum kita melihat adanya dugaan heteroskedatisitas kita harus melihat terlebih dahulu adanya potensi dari heteroskedatisitas. Kita tahu adanya variance yang berbeda antara Y prediksi. Tentu untuk meminimalkan kita bisa menghilangkan hal tersebut. Penyebab dari terjadinya heteroskeditas adalah nilai yang ekstrim atau outlier dalam data. Maka data outlier tersebut jauh dari peramalan sedangkan kita sulit untuk membuat ramalan yang tepat. Dalam hal ini kitameyakini tidak adanya heterosekdatistiasta dalam model ini menggunakan uji studentdized Breusch-Pagan Test. Dalam uji ini RStudio akan mengelola nilai galat tersebut. DAri uji maka Ho ; Tidak Terjadi Hteroskedatisitas H1 : Terjadi Heteroskedatitisitas Kalau nilai peluang (p-value) &gt; dari 0,005 maka kita akan menerima HO library(lmtest) bptest(regresimtcars1) ## ## studentized Breusch-Pagan test ## ## data: regresimtcars1 ## BP = 5.3769, df = 2, p-value = 0.06799 Di awal mungkin kita tidak bisa untuk menebak atau menduga apakah yang terjadi dalam regresi kita tetapi kita bisa lakukan antara lain Plot scatter antara predictor value dan residual kalau memuat grafik seperti pola topi runcing atau cone, maka akan adanya heteroskedatisitas Plot scatter antara nilai yang diprediksi dan residual kalau berbentuk seperti pola tertentu bisa jadi pola sebaran itu seperti ada garis yang mempunyai trend cenderung ke atas atau ke bawah. Ada sekumpulan garis residual yang membentuk suatu pola. Tentu hal ini tidak baik karena menunjukkan adanya pola tertentu. kita bisa melakukan seperti mmembuat plot dari taksiran dan juga residual Marliana (2017). Breusch pagan dan white test adalah untuk mendeteksi adanya heterosskedatisitas dengan cara menghitung. BReusch Pagan akan menghitung nilai (5.2) \\[\\begin{equation} BR= n.R^2 \\tag{5.2} \\end{equation}\\] Setelah kita mengetahui adanya gejala heteroskedatisitas maka kita harus memperbaiki hal tersebut. Ada beberapa hal namun sebelum kita memperbaiki kita harus melihat dulu mengapa terjadi heteroskedatistas residuals(regresimtcars1) ## Mazda RX4 Mazda RX4 Wag ## -0.84395255 -0.84395255 ## Datsun 710 Hornet 4 Drive ## -3.28885510 1.57324352 ## Hornet Sportabout Valiant ## 4.14732774 -2.40601638 ## Duster 360 Merc 240D ## -0.25267226 -0.89226849 ## Merc 230 Merc 280 ## -2.61371193 -2.48751693 ## Merc 280C Merc 450SE ## -3.88751693 0.11418581 ## Merc 450SL Merc 450SLC ## 1.01418581 -1.08581419 ## Cadillac Fleetwood Lincoln Continental ## -1.84730532 -2.09430892 ## Chrysler Imperial Fiat 128 ## 1.79401841 5.70804444 ## Honda Civic Toyota Corolla ## 3.64629354 7.05160883 ## Toyota Corona Dodge Challenger ## -4.33979314 0.08281514 ## AMC Javelin Camaro Z28 ## -0.50535572 -1.45850859 ## Pontiac Firebird Fiat X1-9 ## 5.47067308 0.61421953 ## Porsche 914-2 Lotus Europa ## 0.16432359 4.04561603 ## Ford Pantera L Ferrari Dino ## 1.06207504 -2.45270705 ## Maserati Bora Volvo 142E ## -0.76710662 -4.42126787 taksiran&lt;-fitted(regresimtcars1) kresid=residuals(regresimtcars1)*residuals(regresimtcars1) plot(taksiran,kresid) Hetereoskedatisitas mengakibatkan peramalan menjdi bias membuat estimasi tidak efisien. Dalam regresi heteroskedatisitas mengakibatkan nilai t akan besar sehingga seolah terlihat nilai yang sangat signifikan. Nilai tersebut tentu tidak baik dan tidak mencerminkan nilai yang sesungguhnya. Supranto Ibarat memperbaiki Kursi Ketika kita memperbaiki suatau gejala contoh autokorelasi bisa jadi heteroskedatisitas yang tadinya belum ada akan muncul. Hal ini bisa terjadi kalau perbaikan pada kita seperti kita memukul kayu di suatu tempat maka akan ada yang terpukul di lain pihak hal itu biasa saja dalam praktik untuk membuat suatu model yang tepat . Maunya kita membetulkan satu namun tidak merusak yang lain tapi itu tidak bisa terjadi. Kalau kita mengetahui akar masalahnya maka kita akan bisa menyelesaikan masalahnya. Terkadang beberapa hal yang banyak yang sudah kita laakukan namun belum memasukkan atau belum menemukan suatu model yang sudah terbebas dari keseluruhan asumsi normal yang menjadi syarat dalam regresi sudah terbebas. Baru model tersebut dapat dikatakan menjadi estimator atau penduga yang baik. Untuk itu memang perlu kesabaran dari proses pengolahan data tersebut. Karena adalah hal yang ketentuan bisa menjadi berubah maka hal itu harus melewati revisi juga. Regresi linier sederhana Regresi linier bergabda Asumsi Normal V V Multikolinearitas X V Heteroskedatiositas V V Autokorelasi V V 5.4 Asumsi Normalitas Kembali lagi ke dalam stataistik dasar kalau kita tahu bahwa regresi tersebut juga memiliki data yang normal atau normalitas. Nilai residual dari peramalan tersebut terdistribusi normal. Jadi bukan datanya yang terdistribusi normal. Ketika hasil regresi linier berganda ini adalah kita akan melihat nilai residual adalah normal atau terdistribusi normal. Data yang normal adalah data yang tersebar menurut seperti lonceng tersebut. Data yang tidak tersebar normal berarti ada sesuatu yang tidak sesuai. Karenannya hasil prediksi dari data tidak normal menjadi tidak konssten. Untuk membuktikan kalau sebuah hasil residual terdistribusi normal maka kita bisa melihat dari table satu grafik batang yang menunjukkan sebaran yang normal. Sebaran normal seperti bentuk gunung yang simetris atau lonceng yang simetris. Baik sisi Kanan dan kiri mempunyai dua sisi yang terbagi sempurna. Kalau sudah seperti ini mska data akn tersebar normal. Pada dasarnya kita sulit sekali mendapatkan sesuatu ynag normal. Terkadang dan memang seringnya muncul grafik yang tidak normal. Hal ini biasa saja karena persebaran data tersebut sering tidak normal apalagi kalau menggunakan data yang dalam jumlah terbaras. Ada kemungkinan data akan mempunyai banyak outlier yang akan menyebabkan residual malah tidak baik model permalannya KIta menggunakan uji Shapiro test akan seperti ini adalah Dalam melakukan uji regresi kita harus memastikan kalau data tersebut juga harus mempunyai normal.Data yang tersebar normal ini penting untuk memastikan kalau hasil regresi tersebut menjadi sah. Untuk melakukan itu kita bisa melalukan uji baik dengan test Shapiro-Wilk Normality Test atau kita juga menggunakan qqnorm atau qqline dari reisudal tersebut. Melakukan uji normalitas pada data dengan Shapiro Wilk test adalah dengan mengetikan perintah shapiro.test terhadap residual regresi mt cars. Dari sana terlihat output tersebut shapiro.test(residuals(regresimtcars1)) ## ## Shapiro-Wilk normality test ## ## data: residuals(regresimtcars1) ## W = 0.9419, p-value = 0.08479 Kita juga dapat melihat dengan plot ini untuk meyakinkan kalau data tersebar normal. Hasil nilai dari Shapiro adalah 0,9419. Dalam uji ini Nilai Ho adalah Data tersebar normal sedangkan Hipotesis Alternatif (Ha) dari uji ini adalah data tdiak tersebar normal. Aturan dalam uji ini jika nilai p (P-Value) ebih besar dari 0,05 (p&gt;0,05) maka keputusan dari uji ini dalah tidak bisa menolak HO. Artinya Data pada reiduals ini adalah tersebar dengan normal. Selain itu kita bisa melakukan dengan grafil normal qq plot. Dengan data itu kita bisa untuk melihat adanya data yang tersebar normal. Kita bisa menggunakan perintah qq normal dengan residuas. Kemudian kita bisa menambahkan qqline. Agar terlihat garis data normalitasnya. qqnorm(residuals(regresimtcars1)) qqline(residuals(regresimtcars1)) References "],["regresi-logistik.html", "Chapter 6 Regresi Logistik 6.1 Contoh Regresi Logistik dalam Rstudio 6.2 Bagaimana interprestasi model ?", " Chapter 6 Regresi Logistik Dalam regresi logisitik kita akan membuat sesuatu variabel logistik atau logit yang berbeda dengan regresi linear . Hal ini berbeda karena regresi linear biasa menggunakan variabel rasio. Untuk regreesi logistik kita dapat memberikan variabel indepnden antara 0 atau 1. Pemilihan variabel independen ini hanya dua saja biner atau (binary), misalnya antara laki dan perempuan, sakit dan sehat, sejahtera dan non sejahtera dan lain-lain. Adapun untuk variabel dependen maka hal itu dibolehkan berupa data rasio Terkadang ada juga data yang menggunakan data yang lain juga. Hal ini bergantung dengan kebutuhan penelitian yang ada. Tetapi pada beberapa kasus bisa jadi regresi yang dilakukan adalah regresi kategorik juga. Kita bisa mengembangkan model dari variabel independen yang akan kita cari prediksinya dengan beberapa faktor independen yang diduga dapat untuk mempengaruhi dari nilai variabel Y tersebut. Hal itu bisa kita lihat dalam studi mengenai regresi logistik tersebut yang ada di jurnal. Kita sambungkan teori dengan penerapan regresi logistik. Regresi logistic sebagai reposn dari keterbatasan regresi linear. Ada nilai yang sebagai variabol explanatory yang berkisar anatara pilihan nilai 1 dan juga nilai 0 saja. Wooldrige (2012) 6.1 Contoh Regresi Logistik dalam Rstudio Untuk melakukan hal ini kita menggunakan dataset dari mtcars . kita menjadikan variabel am atau automatic machien 1 untuk nilai automatic sedangankan ) untuk nilai non automotaic. dari sini kita melihat bahwa peluang probabilitynya adalah kalau nilai variabel independennya am satu adalah dipengaruhi dengan nilai wt yang seara signifikan. Maka jdul berat adalah mempengaruhi terhadap mesin. sedangankan mpg atau jumlah minyak per gallon (mill per gallon) adalah tidak berpengaruh signifikan pada probabailitas dari nilai mesin automatik. modellogitcar &lt;- glm(am ~ mpg + wt + hp, data = mtcars, family = binomial) summary(modellogitcar) ## ## Call: ## glm(formula = am ~ mpg + wt + hp, family = binomial, data = mtcars) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -15.72137 40.00281 -0.393 0.6943 ## mpg 1.22930 1.58109 0.778 0.4369 ## wt -6.95492 3.35297 -2.074 0.0381 * ## hp 0.08389 0.08228 1.020 0.3079 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 43.2297 on 31 degrees of freedom ## Residual deviance: 8.7661 on 28 degrees of freedom ## AIC: 16.766 ## ## Number of Fisher Scoring iterations: 10 Uji Asumsi model Setelah kita melakukan regresi maka kita bisa menguji asumsi model yakni beberapa model dengan uji multikolinearitas seperti kita harus mempunyai package car. kalau belum punya maka kita harus menginstall terlebih dahulu library (car). ada beberapa tahapan lagi yang bisa kita untk menguji seperti yang ada di artikel Alice (2015) library(car) vif(modellogitcar) ## mpg wt hp ## 15.545025 1.762413 18.073863 Hasil menunjukkan nilai dari vif terlalu besar untuk variabel mpg dan Hp yakni 15,54 dan juga nilai untuk VIF hp adalah 18.073863 maka dengan demikian kita akan berkihtirar dengan menghilangkan nilai mpg atau nilai hp di contoh bawah akan saya hilangkan sehingga mmepunyai persamaan yang baru. modellogitcar2 &lt;- glm(am ~ mpg + wt, data = mtcars, family = binomial) summary(modellogitcar2) ## ## Call: ## glm(formula = am ~ mpg + wt, family = binomial, data = mtcars) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 25.8866 12.1935 2.123 0.0338 * ## mpg -0.3242 0.2395 -1.354 0.1759 ## wt -6.4162 2.5466 -2.519 0.0118 * ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 43.230 on 31 degrees of freedom ## Residual deviance: 17.184 on 29 degrees of freedom ## AIC: 23.184 ## ## Number of Fisher Scoring iterations: 7 vif(modellogitcar2) ## mpg wt ## 3.556491 3.556491 Nilai dari vif sudah berkurang menjadi 3,556491 baik mpg maupun wt. maka dengab pengurangan variabel hp dapat untuk menurunkan hubungan atau korelasi anatara variabel mpg dengan hp tersebut. Selanjutanya adalah kita akan melanjutkan dengan berbagai asumsi yang lain. 6.2 Bagaimana interprestasi model ? Hasil regresi menghasilkan beberapa nilai yang perlu dianalisis . Nilai-nilai tersebut sama-sama seputar regresi namun karena adanya nilai dikotomi maka kita ajan sedikit berbeda untuk Apakah kita akan membedakan analisis dua data kategori tersebutnya. Tentu hal itu akan dibicarakan dan akan dijelaskan dari nilai dikotomi tersebut. Misalnya untuk regresi yang nilai angka 1 dan angka 0 maka kita harus memperhatikan kedua dikotomi tersebut. Ada hal yang membedakan karena dari awalnya memang untuk melihat pengaruh antara dua variabel kategori tersebut. Mungkinkah dari hal tersebut kita bisa memberikan interprestasi yang berbeda? Pada hubungan antara variable dependen dengan variable independen maka kita melihat nilai dari signifikasi dari hubungan atau relasi antara variable dependen dengan variabel independennya. Kita melihat nilai p value atau Probability value. Seperti sudah menjadi kebiasaaan kalau nilai pvalue tidak boleh lebih dari 0,05 atau 5%, Kemudian melihat table ANOVA apakah nilai model sudah sesuai dengan harapan. Nilai ini menghitung kalkulasi perbedaan antara variabel dependenden maupun variabel independen. Hipotesis nol adalah tidak terjadi perbedaan yang artinya seluruh rata-rata dari nilai akan menjadi sama. Sedangkan pada hipotesis alternatif atau Ha adalah setidaknya ada satu variabel yang memiliki nilai yang berbeda. Adapun persamaan dari nilai logisitik adalah seperti ini @(eq:logistic) \\[\\begin{equation} P(Y = 1 \\mid X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_k X_k)}} \\tag{6.1} \\end{equation}\\] \\[ \\begin{align*} \\text{Keterangan:} \\\\ P(Y = 1 \\mid X) &amp; : \\text{Probabilitas bahwa variabel dependen } Y \\text{ bernilai 1, diberikan nilai } X. \\\\ \\beta_0 &amp; : \\text{Intercept (konstanta), yaitu log odds ketika semua } X_j = 0. \\\\ \\beta_1, \\beta_2, \\ldots, \\beta_k &amp; : \\text{Koefisien regresi untuk masing-masing variabel independen.} \\\\ X_1, X_2, \\ldots, X_k &amp; : \\text{Variabel independen (prediktor).} \\\\ e &amp; : \\text{Basis logaritma natural, dengan nilai mendekati } 2.718. \\\\ z &amp; = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_k X_k : \\text{Kombinasi linear dari model.} \\\\ \\end{align*} \\] Pada bagian variabel independen atau juga variabel bebas aka ada nilai p/(1-p) maka hal itu adalah perbandingan anatara variabel dikotomi dalam variabel independen tersebut. Misalnya kita menetapkan p itu sebagai sukses maka nilai (1-p) adalah nilai non sukses atau gagal. Contoh juka demikian kita dapat menulis kemungkinan sukses atas kemungkinan gagal. Kalau kita tetapkan kemumgkinan sukses tersebut adalah 0,7 maka kita bisa masukkan nilai sebagai berikut 0,7/(1-0,7)= 0,7/0,3 = 2,33 . hal ini berarti kita bisa artikan kalau nilai kesuksesan mempunyai peluang 2,33 kali lebih banyak daripada kegagalan. Begitu juga nilai tersebut kita bisa gunakan yang lain untuk memasukkan nilai p sebagai nilai untuk satu peluang yang sudah saya tunjuk. Perbandingan rasio antara sukses dan tidak sukses disebut juga odds. Persamaan logistik Dalam regresi logistik tidak perlu lagi untuk melakukan ujian asumsi klasik seperti yang dialkukan pada regresi linear lainnya. Hal ini mungkin dikarenakan karena sifat nilainya yang sederhana sehingga berbeda. Variabel dikotomi yang lebih sederhana membuat erro mungkin tidak seberapa besar dengan regresi linear. Meski tidak menggunakan model asumsi linear akan tetapi ita tetap saja memerlukan untuk menggunakan nilai chi Square. Hal ini penting juga untuk menilaid ari regresi tersebut. Hal ini cukup sebagai tujuam uuntuk mendapatkan nilai regresi tersebut. Untuk langkah-langkah dalam regresi logistik ini kita bisa lakukan sebagai berikut : 1. Mengumpulkan data menegnai variabel bebas maupun variabel tidak bebas dan mendapatkan seluruhnya ke dalam suatau tabulasi yang baik. Yakinkan data sudah terhitung dengan benar sesuai dengan yang hendak kita carikan. 2. Melakukan regresi logistik menggunakan software yang sudah digunakan sebelumnya. Saya memilih menggunakan R karena lebih mudah. 3. Memastkam nilai dari regresi itu sesuai dengan yang kita iningnkan. Nilai dari regresi terlepas dari beberapa hal seperti nlai Chi square 4. Menginterprestasikan nilai dari regresi logistik dari perhitungan probabilitas dari hasil software. Interprestasi dari hasil regresi logistik Ketika kita sudah mendpatkan hasil regresi maka kita harus tahu untuk menerjemahkan hal ini. Dalam regresi logisitik tidak seperti regresi persamaan yang bentuknya linear. Kalau dalam regresi linear variabel bebas dapat memepengaruhi dalam besaran sekian berkat dari nilai koefisien yang ada dalam persamaan tersebut. Tetapi karena ada dua dari jenis dari variabel independen. Maksudnya ada dua kemungkinan binary atau dua peluang ketika seorang untuk memeilih nilai satu atau dua saja. Mudah seperti itu maka interprestasinya dalah seperti ini. Kalau saya mencontohkan dengan anak yang luslu maka anak yang lulus harus mempunyai syarat seperti nilai ujian yang bagus, kehadiran yang menutupi yang lain. Ketika itu kita dapat memilih peluang dari anak yang akan khusus dari nilai ujian Mata Kuliah Ujian tertentu harus memenuhi beberapa hal. Untuk yang sederhana saja kita bisa mencari hubungan perokok dengan usia yang ada. Apakah kita hubungkan anatar usia sebagai varabel bebas berhubungan dengan variabel yang kita cari. Tentu kita masih memetingkan apakah nilai signifikan dari variabel tersebut karena kalau tidak signifikan maka kita tidak bisa untuk memprediksi dari nilai tersebut. Misalnya saya akan meprediksi nilai kebangrkutan dari persauaahn dengan nilai seperti ini: Log(p/(1-p) = b0 + b1*ROA Nilai p adaah nilai peluang perusahaan mengalami kesulitan keuangan, b0 adalah nilai konstanta dan b1 adalah nilai koefiseien dari variabel bebasnya, dalam hal ini variabel bebasnya adalah Return on Assets (ROA). Untuk kta melakukan interprestasi adalah seperti dibawah ini . Nilai intercept atau kosntanta adalah nilai yang masih ada ketika nilai ROA menjadi nol. Apakah mungkin nilia tersebut atau nilai ROA itu bisa nol. INi mungkin saja karena ada perusahaan yang tidak menghasilkan nilai keutnungan atau nilainya menjadi nol sehingga pendapatan dari perusahaan tersebut adalah nol. Kemudian adalah nilai koefisein dari ROA ini adalah seebrapa besar pengaruh jadi bukan menunjukkan kuatnya hubungan melainkan nilai besaran yang mempengaruhi rasio logit tersebut. Tentu menerjemahkan dari persamaan itu butuh berupa hasil. Katakanlah jika kemungkinan dari financial distress itu hanya 0,1 maka peluang maka ada kemungkinan kebangkrutan itu hanya sekitar 0,11 kali karena dari nilai 0,1/0,9 maka akan ada nilai yang besar sekali. (kutipan) Dalam regresi logisitik ada berapa asumsi yang bisa kita penuhi antara lain: 1. Error harus berdistribusi normal 2. Heterosedatisitas 3. Hubungan variable bebas dan tidak bebas yang ternyata tidak linear Pertanyaan 1. Apa Perbedaan Regresi Liniear dan Regresi Logistik? 2. Apa definsi dari regresi logistic? 3. Apa tahapan dalam regresi logistic? 4. Setelah mendapatkan nilai regresi logsitik maka bagaiaman kita meyakinkan kalau nilai hasil regresi kita sudah terbebas dari asumsi yang buruk? 5. Apa saja yang bisa kita tafsirkan jika kita mendapatkan hasil regresi demikian 6. Bagiaman cara memprediksi probabilitas kejadian dari model regresi logisitik ? 7. Jelaskan bagaiman menetapkan nilai 1 dan 0 pada variable independn tersebut? 8. Bagiaman penerapan regresi logsitik dari bidang manajemen ? 9. Apa yang dimaksud odds ratio dan mengapa itu penting? 10. Bagiaman cara pemilihan variable dalam regresi logistic? References "],["regresi-dengan-data-kategori-dummy.html", "Chapter 7 Regresi Dengan Data Kategori (Dummy)", " Chapter 7 Regresi Dengan Data Kategori (Dummy) Regresi dummy Kalai kota menetapkan Y sebagai variabel kategoriknitu berarti kita melakukan regresi logistik atau logit. Hanya saja ada yang masuk dalam variabel kategorik yang bisa kita gunakan untk menyelidiki hubungan kategorik dengan varoabel tertentu. Dalam regresi linear menggunakan data kategori sebagai variable independent dengan menamakan huruf satu dengan variable tertentu dan angka 0 untuk variable lainnya. Contoh perempuan yang cenderung rajin daripada laki-laki akan menghasilkan nilai yang lebih baik dari laki-laki. Tentu kasus per kasus akan berbeda dengan yang lainnya karena bisa jadi di beberapa bagian lelaki akan ada yang mempunyai prestasi lebih baik. Off course, kita bukan bicara mwngenai hal itu karena Statistik itu akan bicara banyak sample yang mewakili. Variabel kategori atau disebut dummy ini memang akan membuat sesuatu yang berbeda dengan variable yang lainnya. VAriabel ini bukan masuk dalam variable angka atau kuantitaif melainkan ini adalah variable Hal itu karena antara dua kategori itu ada hal yang berbeda seperti laki-laki dan perempuan. Pemaksaan untjk mencari nilai akan membuat sesuatu menjadi terpaksa dan akan terjadi nilia residual yang sangat besar sekali dan patutu diduga model regresi akan bias tidak memenuhi BLUE. Adanya aktegori ini sedikitnya melonggarkan .dalam satu persamaan ada aetidkanya dua kategori kalau dalam satu variabel. Maka kita akan membedakan anatara laki-laki dan perempuan. Untuk memudahkan maka si peneliti akan memberikan angka 0 untuk perempuan dan angka 1 untuk laki-laki. Seperti habg kita sudaj bahasa sebelumnya jika nilai peramalan atau corecast dari perempuan hanya berupa Beta Sajam karena nilai 0 akan menihilkan angka X maupun nilai Beta yang ada dalam persamaan. Sedangkan untuk nilai laki-laki akan mendapatkan tambahan dari Beta selain nilai dari alpha tentunya. Apakah model Dummy selalau dipakai. Hal itu tentu dengan kebutuhan yang ada. Kalau terajdi perbedaan yang behitu signifikan maka kita akan menggunakan hal seperti itu tetapi kalai kita yka wlihat hal yang penting maka kita pehih baik tidak usah memakai dummy. Bagaiaman anda membuat model? Membuat model bagi seorang yang pemula dan peneliti pemula adalah dengan menggunakan model yang sebelumnya. BUkan menyalin adalah sesuatua yang mudah. setidaknya dalam menggunakan model yang sudah ada karena model tersebut sudah terbukti . Kalau belum terbukti atau merancang memang akan sulit sekali dengan demikian. misalnya kita sudah pasti tdak ada perbedaan aanatara kecerdasan wanta dan laki-laki dalam ilmu bahasa maka akan sulit sekali mmenggunakan hal itu untuk membedakan anytara satu dengan yang lainnya. HAl itu menjadi percuma saja kalau kita tidak menemukan hal yang membedakan dalam modle tersebut maka lebih sederhana saja kita tidak usah untuk membuat modle sperti itu. KIat tinggal menggunakan regresi yang sudha biasa diguankan saja yang lebih sederhana maka itu akan lebih baik dan tidak perlu untuk membuat teori yang baru. Ketika anda bisa untuk mencari model yang membutuhkan dummy maka anda sebaiknya juga dapat mengikuti hal itu. HAl seperti ini Ketika sebuah regresi tidak memenuhi syarat kita mungkin bertanya apakah penyebabnya? Padahal kita sudah memenuhi asumsi yang sudah kita penuhi sebelumnya . Kita sudah melakukan perbaiki asumsi yang sudah ditetapkan. Permasalahan adalah bukan karena datanya. Kita sudah sepakat kalau data adalah netral. Ia seperti halnyaa bahan makanan yang segar tentu saja kalau anda memilih data yabg benar Data yang salah akan menghasilkan olahan yang salah. Sama seperti telur busuk yang akan menghasilkan kue yang dihasilkan dari telur busuk. Bagaimana rasanya? Pasti rasanya sudah tidak bagus lagi. Hal ini karena sudah buruk. Dalam membuat suatu model maka kita juga harus memperhatikan model yang sebelumnya sudah ada ini penting juga. Sebaiknya kita sudah mencontoh apa model apalagi hanya dalam tataran sekolah sarjana saja. Dengan mencontoh model bukan berarti plagaitor karena model yang sudah ada bisa menjadi rujukan bagi kita untuk menjadikan sebuah penelitian yang akan kita lakukan. Jika seorang peneliti muda maka mereka seharusnya membuat yang mirip saja atau duplikasi saja. Ketika kita memilih regresi maka kita tahu bahwa akan memeriksa hubungan antara satu faktor dengan faktor yang lainnya. Apakah ada hubungan dengan hubungan yang lain? Karena itu memang ada hubungannya dengan hubungan yang lain. Kalau tidak ada hubujgan dengan yang lain maka kita tidak bisa memeriksakannya. Kalaupun memqksakan visa jadi ada hubungan seperti yabg saya jelaskan namun hubunga tersebut tidak bisa valid. Salah satu cara meyakini adalah denga literatur. LIteratur tersebut adalah landasan kita untuk membuat Kira aka. Membagi beberapa hal yang bisa kita bagikan. Dalam hal ini kita menggunakan variabel dummy atau variabel boneka. Variabel ini menggunakan angka 10 dan 0. Lalu bagaimana penetapannya. Umumnya dua angka ini untuk membedakan. Jangan kita membuat sendiri tanpa adanya pertimbangan yang matang dengan hal itu. Kita harua bisa memberikan pertimbangan yang pas bagi model yang kita bangun. Sebab namanya statistik bisa dibuat apa saja. Setelah itu kita membagi kategori itu. Berapa yang hendak kita gunakan kategori. Kalau kita hanya menggunakan dua kategori maka kita hanya membutuhkan satu data dummy saja. Kalau kita mempunyai tiga kategori maka kita setidaknya bisa untuk membuat dua variabel dummy saja. Maka kalau kita mempunyai beberapa kategori kita akan membuat dengan banyaknya kategori dikurangi satu atau variabel atau banyaknya variabel dummy = kategori - 1 Maka kita juga ahrus bijak dalam menggunakan variabel dummy tersebut karenan banyaknya akan kemungkinan membuat asusmi regresi bisa menjadi tidak terpenuhi terutama adalah masalah multikolinearitas. Maka kita harus membuatnya sesuai dengan kndis dan pemenuhan data. yang ada . Misalnya kita ingin membuat kategori pendidikan dari tiga tingkatan stratat yakni kategori bawah sarhjana , kategori sarjana , dan kategori di atas sarjana maka akan duibuat dua dummy variabel. yakni Y= a + b1.X1 + b2.D1.X + b3.D2.X + e kategori satu akan saya masukkan untuk sarhana sedangkan kategori dua adalah master maka yang bukan sarjana akan masuk dalam kategori tersebut. HAsilnya kita akan bsia melihat bahwa dnegan adanya data dummy tersebut maka saya bisa memprediksi ada perbedaan anatara beberapa kategori tersebut. #Regresi Data mytcars dengan variabel dummy mtcars ## mpg cyl disp hp drat wt qsec ## Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 ## Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 ## Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 ## Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 ## Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 ## Valiant 18.1 6 225.0 105 2.76 3.460 20.22 ## Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 ## Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 ## Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 ## Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 ## Merc 280C 17.8 6 167.6 123 3.92 3.440 18.90 ## Merc 450SE 16.4 8 275.8 180 3.07 4.070 17.40 ## Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 ## Merc 450SLC 15.2 8 275.8 180 3.07 3.780 18.00 ## Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.250 17.98 ## Lincoln Continental 10.4 8 460.0 215 3.00 5.424 17.82 ## Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 ## Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 ## Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 ## Toyota Corona 21.5 4 120.1 97 3.70 2.465 20.01 ## Dodge Challenger 15.5 8 318.0 150 2.76 3.520 16.87 ## AMC Javelin 15.2 8 304.0 150 3.15 3.435 17.30 ## Camaro Z28 13.3 8 350.0 245 3.73 3.840 15.41 ## Pontiac Firebird 19.2 8 400.0 175 3.08 3.845 17.05 ## Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 ## Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 ## Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.50 ## Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.50 ## Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.60 ## Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.60 ## vs am gear carb ## Mazda RX4 0 1 4 4 ## Mazda RX4 Wag 0 1 4 4 ## Datsun 710 1 1 4 1 ## Hornet 4 Drive 1 0 3 1 ## Hornet Sportabout 0 0 3 2 ## Valiant 1 0 3 1 ## Duster 360 0 0 3 4 ## Merc 240D 1 0 4 2 ## Merc 230 1 0 4 2 ## Merc 280 1 0 4 4 ## Merc 280C 1 0 4 4 ## Merc 450SE 0 0 3 3 ## Merc 450SL 0 0 3 3 ## Merc 450SLC 0 0 3 3 ## Cadillac Fleetwood 0 0 3 4 ## Lincoln Continental 0 0 3 4 ## Chrysler Imperial 0 0 3 4 ## Fiat 128 1 1 4 1 ## Honda Civic 1 1 4 2 ## Toyota Corolla 1 1 4 1 ## Toyota Corona 1 0 3 1 ## Dodge Challenger 0 0 3 2 ## AMC Javelin 0 0 3 2 ## Camaro Z28 0 0 3 4 ## Pontiac Firebird 0 0 3 2 ## Fiat X1-9 1 1 4 1 ## Porsche 914-2 0 1 5 2 ## Lotus Europa 1 1 5 2 ## Ford Pantera L 0 1 5 4 ## Ferrari Dino 0 1 5 6 ## Maserati Bora 0 1 5 8 ## Volvo 142E 1 1 4 2 library(lmtest) library(zoo) #Kita regresi dengan data nominal atau dummy #mengecek apakah ini variabel kategori is.factor(mtcars$vs) ## [1] FALSE #mengecek jenis atau kelas dari data class(mtcars$vs) ## [1] &quot;numeric&quot; #mengecek tipe variabel str(mtcars$vs) ## num [1:32] 0 0 1 1 0 1 0 1 1 1 ... #untuk mengecek semua data bisa kita lakukan seperti ini sapply(mtcars,class) ## mpg cyl disp hp drat ## &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; ## wt qsec vs am gear ## &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; ## carb ## &quot;numeric&quot; #atau sapply(mtcars,is.factor) ## mpg cyl disp hp drat wt qsec vs am ## FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## gear carb ## FALSE FALSE #saya merubah faktor ke dalam bentuk kategorik (dummy) mtcars$vs &lt;- factor(mtcars$vs, levels = c(0, 1), labels = c(&quot;0&quot;, &quot;1&quot;)) library(car) modeldummy&lt;-lm(log(mpg)~wt+vs+disp,data=mtcars) summary(modeldummy) ## ## Call: ## lm(formula = log(mpg) ~ wt + vs + disp, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.14610 -0.09242 -0.03506 0.06273 0.27415 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.6181792 0.1042305 34.713 &lt;2e-16 *** ## wt -0.1792410 0.0501582 -3.574 0.0013 ** ## vs1 0.1033651 0.0636280 1.625 0.1155 ## disp -0.0005601 0.0004681 -1.197 0.2415 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1222 on 28 degrees of freedom ## Multiple R-squared: 0.848, Adjusted R-squared: 0.8317 ## F-statistic: 52.07 on 3 and 28 DF, p-value: 1.412e-11 library(ggplot2) ## Warning: package &#39;ggplot2&#39; was built under R version ## 4.3.1 vif(modeldummy3) ## wt vs disp ## 5.003628 2.136495 6.991296 dwtest(modeldummy) ## ## Durbin-Watson test ## ## data: modeldummy ## DW = 1.8534, p-value = 0.2565 ## alternative hypothesis: true autocorrelation is greater than 0 bptest(modeldummy) ## ## studentized Breusch-Pagan test ## ## data: modeldummy ## BP = 3.376, df = 3, p-value = 0.3372 "],["regresi-non-linear.html", "Chapter 8 Regresi Non Linear 8.1 Mendeteksi awal", " Chapter 8 Regresi Non Linear Ada bebebrapa hal yang tidak di wakili oleh regresi linear. Ketika regresi linear yang sudah kita pelajari adalah menggambarkan suatau hubungan yang dalam bentuk garis lurus atau linear. Kini dengan adanya non linear maka hal itu masih menjadi kompleks lagi dengan hubungan yang bukan linear atau non linear. Hubungan dalam grafik antara regresi non linear akan berbeda dan bukan lagi digambarkan sebagai garis lurus akan tetapi sebagai garis yang tidak lurus. Regresi adalah salah satu bentuk Akomodasi dari hubungan linier yang tidak bisa diwakili oleh regresi linear Gareth James and Thibsarani (2023) Dalam regresi kuadratik kita dihadapi dengan nilai yang berhubungan tidak bisa liner. Umumnya kudaratik membuat gerakan seperti gerakan parabola yang akan sulit dibaca dengan menggunakan garis yang linier. Memang apakah linier itu selalu hebat? ini menjadi pertanyaan sendiri. Jarang sekali model yang bentuknya kudrat dan itu memang yang sering terjadi karena memang hubungan itu mungkin hampir setara. Mungkin banyak orang yang berpikir kalau kuadrat itu memang tidak umum. Apalagi kalau sudah variable lebih dari satu, hubungan tu akan seperti pencaran yang berbeda-beda. Ada pola-pola hubungan yang tidak bisa digambarkan dengan regresi non linear sehingga tidak menghasilkan regresi linier seperti polynom, logaritmik dan eksponensial. Kalau anda bisa melihat maka anda akan lihat hubungan garis ini tidak normal. Untuk mencari adanya hubungan yang tidak linier kita dapat untuk membuat scatter diagram atau diagram pencar. Ini mungkin tidak Sehariusnya atau awalnya garis dalam hubungan variabel tersbeut lurus namun ternyata tidak lurus. Tentu, tidak semua hubungan akan selalau linear dan juga bukan berarti seluruh hubungan juga non linear. Kita melihat atau mendeteksi dari perubahan apakah ada data yang terlihat berubah secara drastic? Zaman telah berubah karena begitu pesat sekali tekhnologi dnengan nama yang awalnya mesin penghitung (computer) ada yang namanya perhitungan dengan model sederhana namun kini perhitungan tersebut sudah lebih canggih lagi dari keadaan masa lampau. Kalau sekarang begitu banyak software stataistik yang dapat menghitung banyak dengan cepat. karenanya dengan ilmu yang modern tersebut maka bisa untuk mencari hal yang baru dengan perhitungan yang akurat. Awalnya mungkin kita akan kesulitan untuk menentukan apakah akan terjadi regresi linear atau tidak. 8.1 Mendeteksi awal Ketika kita ingin menduga suatau hubungan kita dapata melihat pola hubungan variable bebas terhadap variable tidak bebas atau dependent. Kita akan membuat suatau diagram ppencar yang menunjukkan hubungan antara kedua variable tersebut. Kalau kita melihat dari dataset trees maka kita bisa lanjutakan seperti ini 8.1 plot(trees$Girth, trees$Volume, main = &quot;Scatter Plot of Volume vs Girth&quot;, xlab = &quot;Girth&quot;, ylab = &quot;Volume&quot;, col = &quot;blue&quot;, pch = 19) # Bentuk titik Figure 8.1: Diagram Scatter! Dibawah ini adalah contoh regresi non linear dalam bentuk kurva kuadrat dengan seperti dibawah ini. #Regresi Quadratic data(trees) model_quadratic &lt;- lm(Volume ~ Girth + I(Girth^2), data = trees) summary(model_quadratic) ## ## Call: ## lm(formula = Volume ~ Girth + I(Girth^2), data = trees) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.4889 -2.4293 -0.3718 2.0764 7.6447 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.78627 11.22282 0.961 0.344728 ## Girth -2.09214 1.64734 -1.270 0.214534 ## I(Girth^2) 0.25454 0.05817 4.376 0.000152 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.335 on 28 degrees of freedom ## Multiple R-squared: 0.9616, Adjusted R-squared: 0.9588 ## F-statistic: 350.5 on 2 and 28 DF, p-value: &lt; 2.2e-16 Dalam contoh ini kita menggunakan regresi kuadratik atau pangkat dua untuk menduga pertumbuhan dari pohon. Kita menggunakan dataset trees yang ada di Rstudio. KIta akan mencoba dengabn persamaan Voolume sebagai variabel dependen atau terikat dengan variabel independen Grith. Maka kita bisa mmebuat dengan variabel Grith dalam bentuk kuadrat. Maka dari persamaan regresi yang kita akan menginterprestasikan dari nilai regresi. yakni adalah Volume = 10, 78267 - 2,02914 Girth + 0,254 54Girth^2 Dari Persamaan tersebut kita bisa menduga kaau hubungan dengan Girth adalah negatif namun tidak signifikan. sedangkan References "],["footnotes-and-citations.html", "Chapter 9 Footnotes and citations 9.1 Footnotes 9.2 Citations", " Chapter 9 Footnotes and citations 9.1 Footnotes Footnotes are put inside the square brackets after a caret ^[]. Like this one 1. 9.2 Citations Reference items in your bibliography file(s) using @key. For example, we are using the bookdown package (Xie 2024) (check out the last code chunk in index.Rmd to see how this citation key was added) in this sample book, which was built on top of R Markdown and knitr (Xie 2015) (this citation was added manually in an external file book.bib). Note that the .bib files need to be listed in the index.Rmd with the YAML bibliography key. The RStudio Visual Markdown Editor can also make it easier to insert citations: https://rstudio.github.io/visual-markdown-editing/#/citations References "],["blocks.html", "Chapter 10 Blocks 10.1 Theorems and proofs 10.2 Callout blocks", " Chapter 10 Blocks 10.1 Theorems and proofs Labeled theorems can be referenced in text using \\@ref(thm:tri), for example, check out this smart theorem 10.1. Theorem 10.1 For a right triangle, if \\(c\\) denotes the length of the hypotenuse and \\(a\\) and \\(b\\) denote the lengths of the other two sides, we have \\[a^2 + b^2 = c^2\\] Read more here https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html. 10.2 Callout blocks "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
