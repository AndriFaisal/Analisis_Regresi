# Pendahuluan 

You can add parts to organize one or more book chapters together. Parts can be inserted at the top of an .Rmd file, before the first-level chapter heading in that same file. 

Add a numbered part: `# (PART) Act one {-}` (followed by `# A chapter`)

Add an unnumbered part: `# (PART\*) Act one {-}` (followed by `# A chapter`)

Add an appendix as a special kind of un-numbered part: `# (APPENDIX) Other stuff {-}` (followed by `# A chapter`). Chapters in an appendix are prepended with letters instead of numbers.


Saya juga mencoba yang namanya tabel dari sini saya akan lihat di mtcars di \@ref(tab:nice-tab2)
```{r nice-tab2, tidy=FALSE}
knitr::kable(
  head(mtcars, 10), caption = 'Here is a nice table 2!',
  booktabs = TRUE
)
```
Saya mau menampilkan tabel tanda menaruh kode chunk tabel ada di lihat di \@ref(tab:nice-tab3)

```{r nice-tab3, echo=FALSE}
knitr::kable(
  head(iris, 10), caption = 'Here is a nice table 3!',
  booktabs = TRUE
)
```



# Regresi Linear Sederhana 

## Grafik Pencar atau Scatter Graph
Salah satu hal yang penting adalah ketika kita mau menduga hubungan antara variabel X dengan variabel Y  yakni dengan scatter graph. Dengan gambar yang ada hubungan. Variabel Y akan kita tempatkan di bagian  vertikal atau bagian yang menhadap ke atas sebaliknya dengan bagian X yang mendatar seperti horizontal. 
adapun mengenai scatter diagram saya akan membuat dengan yang namanya data dari mtcars yang berasal dari Rstudio. dalam hal ini saya akan mengunakan Horsepower dan mil peragalon atau mpg\@ref(fig:scatter-fig)

```{r scatter-fig, fig.cap='Diagram Scatter!', out.width='80%', fig.asp=.75, fig.align='center', fig.alt='Scatter Diagram data mt cars.'}
plot(mtcars$hp, mtcars$mpg, 
     main = "Scatter Plot of Horsepower vs MPG",
     xlab = "Horsepower",
     ylab = "Miles per Gallon",
     col = "blue",
     pch = 19) # Bentuk titik
```


Kita memasangkan sesuai dengan pasangan nilai data tersebut X dan Y. Jangan pasang teracak agar kita bisa melihat hubungan antara keduanya. Pasangan data tersebut adalah yang termasuk dalam individu misalnya ada seorang yang mempunyai pendapatan X dengan pengeluaran Y maka nilai itu yang kita pasangkan bukan malah membuat pendapatan seorang tertentu dengan pengeluaran yang lain karena itu akan menjadi berbeda nilainya. 
Dari hubungan tersebut akan membentuk scatter graph. Ada sejumlah titik-titik yang menyebar atau mengumpul di sekitar grafik pencar scatter graph tersebut. Titik titik itu mewakili banyak individu yang memiliki nilai dari kedua variabel X dan Y.
Banyaknya kumpulan titik atau scatter itu bergantung dari banyaknya daat tersebut. Semakin banyak jumlah data yang dibuat sampel adalah dengan dimasukkan dalam grafik tersebut. Ada beberapa hal yang dapat kita pelajari dari scatter plot seperti:
1.	Pola dari titik tersebut mempunyai pola seperti cenderung mengumpul di satu tempat karena nilanya mempunyai yang sama 
2.	Trend. Kita dapat melihat suatu trend ketika ada satu garis yang bisa kita tarik pada titik tersebut dan kita menunjukkan ada yang bisa menunjukan garis ke atas atau bahkan tidak memiliki trend. 
3.	Outlier. Outlier adalah nilai yang terpencil . Ia hanya sendiri dan jauh di pinggir atau ditengah nilai-nilai yang lain karenanya disebut outlier. Outlier tentu sedikit dan ini menyebabkan data tidak normal. 


Regresi Linear adalah salah satu cara untuk melihat hubungan antara variabel bebas dengan variabel tidak bebas. Dalam hal ini yang mempengaruhi adalah variabel yang bebas sedangkan yang dipengaruhi adalah variabel tidak bebas. Dalam regresi hanya mengenal satu arah saja pengaruh yakni variabel bebas terhadap variabel dependen dan bukan sebaliknya. 
Pembatasan itu dengan tegas agar dalam mencari hubungan tidak akan ada kekeliruan. Misalnya pengaruh garam terhadap darah tinggi maka dari sini kita akan mencari hubungan antara garam dengan darah tinggi. Garamlah yang mempengaruhi tingginya tekanan darah (tensi) seseorang. Dengan alasan ilmiah dan penjelasan kalau zat garam akan meningkatkan tekanan darah tersebut. Kita tentu tidak akan menempatkan garam sebagai hal yang dependen tetapi ia adalah sesuatau yang bebas dalam hal ini karenanya ia mempengaruhi tekanan darah tinggi. Apakah ia akan menjadi faktor yang dipengaruhi . Hal itu bisa saja kalau dalam konteks yang lain misalnya kalau garam itu akan dipengaruhi oleh jumlah sinar matahari yang menerpa bumi.
Regresi linear pertama kali dikenalkan oleh Galton @Galton1886 yang menemukan adanya hubungan tinggi anak dengan tinggi orang tuanya. Ia menghitung jumlah banyaknya anak yang mempunyai dengan tinggi orang tuanya. Hal ini berkaiatan dengann keturunan atau hereditas. Galton ingin menemukan apakah ada tinggi orang tua akan mempengaruhi tinggi sang anak.  
Regresi linear hanya memeriksa antara hubungan variabel beas dengan variabel tidak bebas. Dalam regresi ini karena hanya ada satu maka disebut juga regresi linier sederhana (simple linear regression).  Metode seperti ini dipakai seperti di ilmu bisnis, ekonomi, manajemen, komunikasi dan ilmu sosial lainnya. 
Dalam regresi sederhana kita akan menggambarkan hubungan dengan garis y= a+ bx. \@ref(eq:linear)

\begin{equation}
Y = a + bX
(\#eq:linear)
\end{equation}

Persamaan ini dihasilkan dari perhitungan regresi terhadap dua variabel tersbeut. Untuk nilai b diperoleh dengan perhitungan jelaskan dulu mengenai perhitungan ada simpangan x dengan simpangan y dibagi dengan jumlah sample atau n. maka bisa dilihat seperti ini. Kemudian nilai a diperoleh dari nilai y rata-rata dikurangi b dikalikan dengan nilai rata-rata X dan akan kita peroleh  nilai a tersebut. Bisa saja dengan menggunakan nilai perhitungan komputasi seperti Excel atau menggunakan software statistic lainnya. 
Dimana a = nilai intercept atau nilai konstanta
       b = koefisen slope atau kemiringan 
Nilai a adalah konstanta ini adalah nilai awal dari persamaan  suatu garis persamaan regresi tersebut. Nilai ini selalu ada. Hal yang ketika terjadi nilai regresor tersebut nol maka tetap saja nilai untuk Y prediksi tetap ada. Inilah nilai yang dinamakan nilai konstanta. Terkadang nama konstanta atau alpha disebut juga intercept sedangkan Beta dinamakan juga slope parameter atau ada juga yang menamakannya parameter. 

Y (x=0) = a + bx 
Y = a + 0.x = a 
Nilai b ini menunjukkan kemiringan dari garis yang menunjukan hubungan antara y dengan X nilai positif berarti nilai yang menunjukkan seiringan atau hubungan yang sama-sama naik atau sama-sama turun. Ketika variabel independen mempunyai nilai yang positif maka akan merubah juga variabel dependen juga akan turut berubah menjadi positif. Bagaimana kalau nilai alpha menjadi 0 maka nilai persamaan tersebut akan memotong garis x karena tidak ada nilai alphanya. 

Pengaruh nilai independen bergantung dengan koefisein semakin besar maka satau perubahan akan menjadi lebih besar dengan kemiringan yang curam sekali. Misalnya Y = 0,1 + 10 X berarti pengganda dari nilai regresi tersebut akan semakin besar dengan nilai tersebut. Jika nilai kurang dari 1 namun masih nilai positif maka kemiringan tetap ke sebelah kanan jadi nilai X meningkat namun dengan peningkatan nilai tersebut semain kecil bukan besar. Untuk nilai yang negatif menunjukkan nilai tersebut adalah saling bertolak belakang. Ketika variabel independen bergerak naik maka yang terjadi adalah variabel dependen akan menurun dan sebaliknya. Hubungan yang negatif berarti juga saling bertolak belakang dan penambahan variabel independen akan mengurangi variabel dependen tersebut. 

## Keterbatasan Regresi Linear {-}

Metode regresi linear adalah metode yang mendapatkan cara untuk menyelidiki hubungan antara variabel dependen dengan variabel independen . Dengan regresi tersebut kita akan mendapatkan nilai korelasi dari persamaan tersebut. Dari dua data yang disamakan tersebut kita akan mendapatkan suatu persamaan r yang mempunyai nilai -1≤r≤1 dengan perincian terhadap berikut. 

## Perbedaan nilai R2 dengan koefisien Korelasi {-}

Kalau koefisien menyebutkan nilai koefisen menunjukkan banyaknya atau kuatnya nilai regresi tapi hati-hati kalau hal tersebut adalah berhubungan dengan nilai r dengan nilai koefisen regresi. Baik r dan beta adalah koefisien kalau beta adalah koefisien regresi sedangkan nilai r adalah koefisein korelasi. Koefisien regresi adalah menunjukkan besarnya hubungan ada suatu hubungan yang menjadi pengganda (multiplier). Koefisien regresi juga menjadi unsur dalam persamaan regresi.  Hubungan ini menunjukkan akan ada besarnya pengali saja. Sedangkan koefisen korelasi adalah nilai yang menunjukkan adanya seberapa erat hubungan tersebut. 
Nilai koefisein regresi menaksir atau meramal nilai Y terhadap nilai X, sedangkan kalau untuk nilai R tersebut memperkirakan keeratan hubungan. Apakah nilai tersebut mempunyai keeratan dari nilai r tersebut. Nilai dalam korelasi r dapat disimpulkan apakah ada hubungan yang kuat atau sama sekali tidak ada hubungan dalam kedua variabel tersebut. Sedangkan untuk nilai koefisein regresi maka kita akan melihat lebih jauh lagi untuk mengintrepretasikan nilai tersebut. Kita dapat menyimpulkan karena nilai dari data mentah antara variabel X dengan Y sudah berbeda. Karena nilai X dan Y mempunyai perbedaan yang besar sehingga nilai koefisiennya menjadi besar. Setiap pengaruh nilai satu independent maka akan berdampak besarnya sesuai dengan koefisen yang 

### Ketebatasan {-}
Sebagai model awal yang menunjukkan hubungan anatara variabel indpenden dan variable dependen ilmu ini adalah atau metode yang memberikan suatau pengetahunan dalam mencari hubungan tersebut. Ada beberapa variabel yang sebelumnya belum diketahui  ddan mungkin hanya estimasi tersbeut. 
Perhitungan tersebut menghasilkan suatu hubungan yang merata ataupun hubungan seberapa besar pengaruh atau pengganda tersebut dalam koefisien regresi. 

# Regresi Linier Berganda

Suatu faktor bukan dipengaruhi satu faktor saja. Seorang yang sukses bukan berasal dari ayah atau ibu yang sukses saja karena ada faktor lain. Ada anak orang kaya yang menjadi miskin karena tidak bisa mengelola harta ayahnya saja. Pada anak yang miskin ia bisa mendapatkan pendidikan dan ia meraih kekayaan yang melimpah karena keahliannya. Dalam praktik regresi linier sederhana sulit sekali dipraktekkan dan pencarian nilai tersebut hanya sederhana untuk mencari faktor yang dapat mempengaruhi faktor independen lainnya. 

Adanya regresi berganda karena keterbatasan regresi linear itu maksudnya yang sederhana karena tidak mungkin bahwa hal yang mempengaruhi tersebut hanya satu faktor. Sangat sederhana kalau suatu peubah dipengaruhi oleh beberapa peubah yang lainnya. Regresi berganda lebih sulit daripada regresi linier sederhana @Ryan2013
Kita bisa melihat kalau nilai r square itu begitu rendah sekali karena pengaruhnya sedikit sekali. Maka kita harus mencari peubah lain yang akan mempengaruhi juga dan akan meningkatkan nilai R kuadrat. Memang tidak ada jaminan kalau peningkatan variabel atau peubah akan membuat nilai R squared akan meningkat terus. Dalam ilmu pengetahuan kita selalu mengeksplorasi dengan factor-faktor yang lain agar bisa mencari yang paling berpengaruh. Terkadang memang faktor yang diduga tidak berpengaruh maka ternyata membuatnya berpengaruh, Memang dalam regresi kita tidak tahu mana faktor yang paling yang paling berpengaruh tersebut. 
Sampai saat ini belum ada ukuran yang jelas mengenai hal tersebiut kalu dalam penggunaan yang sama. Namun dalam penggunaan determinasi yang satu mungkin akan terlihat mana faktor yang berpengaruh. Tetapi kalau sudah tercampur terkadang sulit juga karena bias, jadi pengaruh tersebut akan berbeda? Kita bisa melihat di persamaan seperti ini \@ref(eq:multiple)

\begin{equation}
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k + \epsilon
(\#eq:multiple)
\end{equation}

di mana:
- \( y \): Variabel dependen.

- \( \beta_0 \): Intersep (konstanta).

- \( \beta_1, \beta_2, \ldots, \beta_k \): Koefisien regresi.

- \( x_1, x_2, \ldots, x_k \): Variabel independen.

- \( \epsilon \): Error (kesalahan residual).


# Persiapan Data 
Sebelum Melangkah ke analisis data regresi kita menggunakan atau mengolah data terlebih dahulu. Kita mengolah data dengan data frame. Lebih baik kita menaruh data di spreadsheet. 
Maka sebelumnya adalah kalau kita mau upload file excel maka kita pastikan bahwa kita mempunyai package read excel maka kalau belum kita install dulu dengan read excel dengan perintah install packages (readxl) setelah itu memastikan dengan library (readxl)
Setelah itu kita pastikan dengan seperti ini 
```{r, eval = FALSE}
# Contoh membaca file Excel di R
library(readxl)

# Jalur file contoh (diperbarui sesuai kebutuhan Anda)
data <- read_excel("path/to/file.xlsx")

# Tampilkan beberapa baris pertama data
head(data)
```

Pastikan kita menemukan path filenya yang benar ke file yang telah kita tentukan sebelumnya. kemudian kita atur input sheetnya kalau file excel tersebut mempunyai banyak sheetnya. Kalau satu biasanya akan diarahkan ke sana. setelah itu kita akan memilih variabel dengan memilih kolom yang sesuai dengan variabel yang hendak kita uji. 
Setelah itu kita bisa menggunakan data set dalam analisis regresi. kalau kita mempunyai package tidy verse maka kita akan mempunyai struktur data yang namanya tibble kalau tidak kita akan mendapatkan data yang namahya data frame.

$$

\begin{bmatrix}
y_1 \\ 
y_2 \\ 
\vdots \\ 
y_n
\end{bmatrix}
=
\begin{bmatrix}
1 & x_{11} & x_{12} \\ 
1 & x_{21} & x_{22} \\ 
\vdots & \vdots & \vdots \\ 
1 & x_{n1} & x_{n2}
\end{bmatrix}
\begin{bmatrix}
\beta_1 \\ 
\beta_2 \\ 
\vdots \\
\beta_n
\end{bmatrix}
+
\begin{bmatrix}
\epsilon_1 \\ 
\epsilon_2 \\ 
\vdots \\ 
\epsilon_n
\end{bmatrix}

$$

Dari matriks kita bisa melihat peramalan dalam meregresi nilai X atau beberapa variabel independen. Kita lihat perhitungannya sampai sudah rumit apalagi dengan banyak sekali variabel yang ada. Kalau regresi dua faktor hanya ada dua dimensi maka akan ada banyak dimensi. Dimensi ini akan mampu menjelaskan hubungan dari variable independent dan juga variable dependen. 
Adapun tujuan dari regresi adalah mencari garis persamaan yang dapat digunakan untuk meramal nilai prediksi Y atau variabel independennya sama seperti yang terjadi pada suatu masa. Terkadang data tersebut akan dapat berguna bagi banyak hal sebagai bentuk untuk menilai kebijakan yang akan diterapkan baik oleh organisasi besar dan kecil maupun juga individual yang akan menentukan kebijakan tersebut. 
Metode regresi linier mempunyai arti adalah untuk mencari hubungan satu variabel tidak bebas atau dependen terhadap beberapa variabel bebas lainnya. Sama halnya regresi sederhana, dalam regresi linier berganda kita akan menguji apakah beberapa variabel bebas akan dapat mempengaruhi dari variabel tidak bebas tersebut. 
Hasil dari regresi adalah    persamaan regresi yang terdiri dari nilai Y terhadap nilai X dengan nilai koefisien seperti nilai variabel satu, variabel dua, dan selanjutnya. Nama dari hasil ini disebut juga persamaan regresi dan juga namanya adalah model regresi.
Jika sudah mempunyai masalah dan ingin mengeksplore variabel atau peubah apa saja yang dapat digunakan untuk regresi maka kita dapat melakukan hal seperti ini. Anda harus tahu bahwa variabel yang akan anda cari adalah variabel yang benar-benar berpengaruh. Kalau variabel asal kita sambungkan saja maka kita tidak akan mendapatkan hal yang seperti harapan kita. Kita mengharapkan akan mendapatkan sesuatu yang baik.
Hal pertama yang kita bisa lakukan adalah mengumpulkan data yang sesuai dengan tujuan penelitian atau variabel yang kita selidiki. Semuanya harus terkumpul.  Semua yang akan dapat kita olah ke dalam regresi tersebut. 
Penting untuk menata data tersebut dan mengorganisasikan data tersebut. Sebelumnya kita lihat terlebih dulu di tabel apakah ada data outlier. Mungkin agak sulit sekali kalau kita mengandalkan tabel untuk mencari outlier. 
Setelah itu kita mengeksplorasi data analisis. Sebelum regresi ini bisa dilakukan bagi yang berpengalaman dari grafik akan dapat menduga apakah semua ini akan menjadi nilai estimasi yang baik atau tidak? Justru awal ini adalah mendeteksi ada kemungkinan kita akan melihat adanya hal yang tidak sesuai dengan data yang hendak kita regresi.
Setelah itu kita bisa melihat adanya outliers. Data di grafik tersebut maka kita akan melihat adanya outlier yang ada. Penting mempertimbangkan adanya outlier ini. Outlier adalah salah satu nilai yang berbeda dari kebanyakan rata-rata. Nilai dari outlier dapat membuat hasil dari model regresi bias. 
Kita harus memastikan data yang kita dapatkan adalah data yang obyektif dan memenuhi syarat. Terkadang kita mengumpulkan data yang salah. Apalagi sampai menggunakan data yang salah ini menjadi permasalahan tersendiri. 
Setelah itu lakukan regresi untuk menghitung atau mengkalkulasi nilai dari persamaan regresi tersebut. Kita akan mendapatkan nilai R kuadrat atau yang dikenal dengan R Square tersebut. Nilai R2 akan mencapai sekitar 100% namun kemungkinan itu tidak ada karena kalau ada yang 100% maka patut kita curigai. Kemudian kita akan mencari nilai F tersebut yang sudah dihitung. Nilai ini adalah nilai signifikasi dari model yang kita buat. 
Setelah itu kita bisa untuk menilai dari variabel yang sesuai dengan nilai signifikasi. Tidak semua yang akan ada akan ada maka akan membuat semuanya signifikan karena ada saja yang hasilmya berbeda sesuai dengan data yang ada. 
Terakhir kita harus melihat juga asumsi model. Kita akan memastikan nilai dari persamaan regresi sudah “benar”. Hasil regresi itu tidak bisa dikatakan benar atau salah karena semuanya ada perhitungannya.

Dalam buku ini selain untuk menggunakan data dari penulis kita juga menggunakan dataset yang ada di Rstudio. Kalau anda mempunyai perangkat maka ada beberapa datasets yang bisa digunakan seperti Chickweights, trees, mtcars, dan lain-lain. Dataset ini sudah rapih tinggal kita bisa menggunakan dalam bentuk beberapa seperti visualisasi, analisis deskriptif, maupun analisis regresi. 

## Paket yang dibutuhkan {-}
Dalam analisis regresi kita bisa membutuhkan paket dalam perangkat lunak **(software)** Statistik Rstudio ini adalah untuk melakukan beberapa regresi seperti halnya:

1. lmtest ; paket ini yang sering digunakan karena memmuat beberapa fungsi seperti lm dan juga glm pada fungsi ini juga memuat bptest dan dwtest

2. car : Paket ini digunakan untuk beberapa fungsi seperti uji durbin watson, multikolinearitas, dan scatterplot matrix.

3. ggplot2 : paket ini untuk membuat visualisasi data atau pembuatan grafik 

Ada banyak sekali package namun tiga paket diatas juga sudah cukup untuk membuat analisis regresi. Banyak sekali package yang ada dan akan selalu berkembang menurut apa yang akan ada dalam Rstudio tersebut. 

## Goodnes of fit

Untuk mendapatkan nilai yang paling baik adalah hal yang diinginkan. Tentu tidak memaksakan sesuatu hal yang akan menjadikan sesuatunya tidak benar atau tidak shahih dan valid. Kita dapat memeriksa nilai dari residu yang merupakan nilai Y aktual dengan Y prediksi atau sering disebut Y topi. Nilai ini merupakan nilai dari total semua residu. Sedangkan di sisi lain adalah kita menilai nilai Y dengan nilai y rata-rata dari variabel Y tersebut yang bisa jadi akan nilainya besar. Kemudian kita juga memperlihatkan nilai selisih antara Variabel Y dengan regresi dalam nilai tersebut nilai SST yang besar sangat diharapkan menandakan nilai yang baik juga. Kemudian ada juga Nilai SSE atau nilai Sum Square Explained adalah nilai yang paling diharapkan tinggi. Ini adalah selisih nilai y aktual dengan nilai y rata-rata. Sedangkan nilai dari SSR adalah sum square dari residual dan nilai ini adalah nilai y prediksi dengan y aktual. 

Sum Square Total = SST = SSR + SSE 
Dari nilai ini kita akan memperoleh nilai R squared atau R kuadrat yang rumusnya adalah SSE/SST. Oleh karena itu yang diharapkan adalah nilai R2 besar sekali. Karena semakin nilai itu besar sekali akan menunjukkan bahwa ada hubungan yang mempunyai poris besar sekali.
Kita juga harus bisa membandingkan dengan nilai adjusted R square yang membandingkan dengan berbagai variabel atau variabel yang lebih dari satu. Cara Adjusted R square ini adalah cara yang lebih konservatif dalam menjelaskan kesesuaian (fit) model. Adapun rumus dari adjusted R Square adalah sebagai berikut  ini: 
Adjusted R2 = 1-[(1-R2)*(n-1)/(n-p-1)]
Nilai ini adalah jumlah obesravsi atau jumlah data yang dilibatkan dalam regresi. Dengan demikian nilai R square adjusted itu lebih digunakan pada waktu regresi terhadapa variable ini lebih dari dua variable bebas. Hal ini ada seperti penyesuaian dengan niai R2 tersebut. 
Nilai yang paling penting adalah nilai F. Nilai yang diperoleh dari nilai ANOVA ini menunjukkan kesesuaian model (fit of model). Kalau nilai dari F signifikan ini lebih kecil dari 0,05 dalam nilai ini adalah nilai yang baik. Kalau sebaliknya nilai peluang (probability value) adalah lebih besar maka tidak diterima model tersebut. Ada yang menjadi masalah dalam model tersebut. Itu yang dapat kita ketahui. Kalau model tersebut mungkin kita pikirkan model yang lain yang dapat kita jadikan model yang baru tersebut. 
Setelah yakin bahwa model tersebut sah kita melihat beberapa variable independent yang diduga mempengaruhi variable dependen tersebut. Kita melihat nilai t yang ada pada bagian setiap variable yang ada. Kalau nilai t hitung dalam hal ini t hitung yang dikalkulasi oleh software. Nilai t itu mempunyai nilai mutlak yang lebih besar daripada nilai table IthitungI > IttabelI. Nilai dalam kurung menunjukan nilai mutlak dari t. Ketika nilai t hitung positif maka nilai yang paling besar juga akan menjadi niai yang paling besar. Kalau nilai negatf maka nilai tersebut nilai yang paling besar. Sejatinya nilai minus yang paling besar adalah nilai yang kecil namun karena masuk dalam nilai mutlak maka nilai minus yang besar menjadi nilai yang paling besar. Masalah penerimaan ini juga bergantung dengan uji nilai yang untuk ditetapkan. Ada uji yang dua arah dan ada juga uji satu arah bergantung dengan kebutuhan yang dibutuhkan oleh regresi tersebut. 
Adapun daerah penolakan tersebut terkait dengan dua arah, Jika berada dalam jangkauan t table maka kita dapat menolak hipotesis yang menyatakan bahwa ada pengaruh pada variable tersebut. 

## Regresi berganda menggunakan data rstudio 

Pada bagian ini saya akan menggunakan data RStudio untuk mendapatkan mengenai rstudio dengan menggunakan dataset yang sudah ada di RStudio yakni dataset yang namanya mtcars. Data mtcars mempunyai beberapa variabel namun sebagai contoh hanya meregresi dua variabel independen saja yakni cyl + disp dengan variabel dependennya adalah mpg atau mile per galon 
```{r}
data(mtcars)
regresimtcars1<-lm(mpg~cyl+disp,data=mtcars)
summary(regresimtcars1)

```


## Istilah{-} 
Korelasi : Hubungan anatara suatau variable dengan suatu variable 

Regresi : Metode Statistik untuk mencari hubungan antara peubah bebas terhadap peubah tidak bebas 

Model regresi : model prediksi yang merupakan hasil regresi 

Outlier : data yang nilainya berbeda dari banyak data umumnya atau rata-ratanya. 

R kuadrat (R^2) : Nilai yang menunjukkan porsi pengaruh variable independent terhadap variable dependen

Adjusted R square : Nilai R kuadrat yang sudah di sesuaikan 

Goodness of fit : Dalam Bahasa Indonesia keseuaian model ini menunjukkan model dari regresi yang sudah sesuai

Scatter Diagram: diagram pencar adalah titik yang menghubungkan antara variabel bebas dan varaibel tidak bebas

## Regresi dengan menggunakan Data Panel 

Mengelola data panel di RStudio untuk mengestimasi persamaan regresi dan mencari pengaruh variable independent terhadapa variable dependen. 
Salah satu metode untuk mencari pengarih variable adalah dengan data panel. Pengaruh seperti ini adalah untuk kita dapat mengestimasi daripada variable dependen. Data panel adalah data kumpulan dalam bentuk 

### Membuat Struktur Data Panel 
Rstudio berbeda dari perangkat lunak (software) statistik lainnya. Untuk mengelola dalam analisis appaun membutuhkan struktur data dalam bentuk rstudio. Kalau software lain cukup menyalin dan menempel (copy and paste) data spreadsheet baik itu Excel atau Google Spreadsheet dan langsung dapat untuk mengelola data namun untuk RStuido harus merubahkan dalam bentuk model data yang dikenal oleh Rstudio. 
Langkahnya adalah mengimpor file speadhheet dan membuat ebberapa pengaturan yang relative mudah untuk membuat data anda mudah diolah. Khusus untuk analisis panel maka yang dibutuhkan bentuk data atau struktur dari data pdata.frame yang merupakan singkatan panel data frame. Ini berbeda dengan data frame biasa di rtsuido karena ini mempertimbangkan dimensi individual dan juga dimensi waktu. Perlakukan inilah yang membuat berbeda. 
Disebelak kana anda dapat mengklik import data set dan pilihlah excel. Ada beberapa pilihan lain seperti spss sas, stata, text dan lain-lain. KAlau mempunyai speadsheet maka pilihlah excel. 
Setelah itu anda akan mmeilih beberapa sheet. Kalau anda bekerja dalam banyak sheet di satu file maka anda harus memilih salah satu sheet. Dibawah itu anda pilih. Maka anda harus meperhatikan kerapihan dari text yang anda buat. Misalnya ada sela diantara judul table dan juga isi data maka di table yang kosong itu akan tertulis NA atau Not Available yang berarti data tidak tersedia. 
Menyiapkan excel sebagai data
Untuk menyusun data maka yang bisa kita lakukan adalah dengan data. Karena data dnegan speadhseet kita lebih mudah. Kita bisa menyusun dengan data seperti contoh dibawah ini

```{r}
tobinq <- read.csv2("~/jurnal/tobinq3.csv")
#setelah data diupload saya akan membuat data frame khusus panel yang disebut pdata frame dengan seperti ini. jangan lupa gunakan library plm
library(plm)
ptobinq=pdata.frame(tobinq,index=c("Comp","Tahun"),drop.index = TRUE,row.names=TRUE)
```
Setelah data sudah benar masuk kita dapat mengecek struktur dari data tersebut
```{r}
str(ptobinq)
```
Sudah benar maka langkahnya adlah mennetukan jenis regresi data panel yang akan kita lakukan. Kemudian sesuai langkah yang sudah kita rencanakan adalah awalnya dengan melakukan regresi dari ketiga metode seperti Pooling (pooling), Fixed Effect (within) dan Random. Dalam contoh kali ini saya akan mennamakan kalau pooling adalah regplmtobinq, untuk fixed effect adalah regplmtobinq2 dan untuk random adalah regplmtobinq3.  Dalam tiap perintah aka nada Namanya perintah summary yang artinya adalah menampilkan hasil regresi tersebut. 

```{r}
#Regresi Model Pooling 
regplmtobinq<-plm(Tobin.Q ~ DAR+DER,data=ptobinq,model="pooling")

summary(regplmtobinq)

#Regresi Model Fixed 
regplmtobinq2<-plm(Tobin.Q ~ DAR+DER,data=ptobinq,model="within")
summary(regplmtobinq2)

#Regresi Model Random Effcet

regplmtobinq3<-plm(Tobin.Q ~ DAR+DER,data=ptobinq,model="random")
summary(regplmtobinq3)

```


##Latihan {-} 
B-S Pada regresi berganda yang menjadi variable independent boleh lebih dari satu sedangkan variabel dependen hanya satu saja. 
B-S Pada regresi variable dependen boeh saja menggunakan variable dummy dan variable gabungan yang lainnya 
B-S Regresi dapat menunjukkan kekuatan dalam satu variable independent terhadap variable dependen
B-S Data outlier adalah data yang berbeda dengan lainnya dan menyebabakan kerusakan dalam regresi. 
B-S Uji t untuk menunjukkan hubungan yang signifikan variable dependen terhadap variable independent 
B-S untuk melihat apakah regresi tersebut sudah baik kita dapat melihat nilai Chi Square
B-S Autokorelasi bias terjadi dalam regresi linier berganda dan dapat menyebabkan kesalahan 
B-S Kalau kita menggunakan variabel dummy adalah variable yang digunakan untuk membedakan antara varabel yang mempunyai kategori. 
B-S Nilai Adjusted R Square selalu lebih besar daripada nilai R Square karena ada tambahan berupa penyesuaian nilai banyaknya variable. 

## Soal{-} 
1.	Buatlah model dengan cara menilai kesehatan tulang untuk yang segar dengan orang yang sakit sehingga bisa mengembangkan dengan bisa membedakan yang berolahraga ataupun yang tidak?

2.	Asumsi apakah yang harus dipenuhi dalam regresi logistik coba jelaskan hal itu?

3.	Pada Altman Z Score setidaknya Z Score dibagi menjadi dua dan ada wilayah abu. saya akan gabungkan wilayah abu ke dalam wilayah yang bangkrut. Akankah ini dibenarkan ? Bagaimana cara menjelaskannya?

4.	Dalam asumsi ternyata tidak ditemukan maka yang sesuai goodnes of fit atau kebaikan model. Bagaimana mengatasi hal tersebut? 

5.	Kalau di regresi logit maka iti kita lihat kalau kita melihat ada yang berbeda maka itu seperti variabel dikotomi maka akan bisa melihat misalnya dikotomi dari kesehatan jantung untuk satu dan kesehatan lainnya?

6.	Pada suatu hasil regresi ditunjukkan nilai R squarenya adalah 75%. Carilah nilai Adjusted R square model tersebut jika jumlah sample 30 dan variable bebasnya ada tiga? 

7.	Carilah contoh beberapa variable independent yang mempengaruhi kepuasan pelanggan?  

8.	Sebutkan beberapa kemungkinan yang ada dari regresi berganda?

9.	Apakah semakin banyak variable independent akan meningkatkan nilai R Square. Coba jelaskan jawaban anda?

10.	Apakah beda korelasi dengan regresi? 

# Asumsi Regresi Linear

Setiap metode yang kita apakah harus kita ingat mempunyau syarat dan kondisi. Seperti kita mau membeli suatu maka kita menemukan suatau kondisi yang harus kita penuhi . Tanpa syarat dan kondisi tersebut maka kita tidak akan mendapatkan apa yang kita maui. Ada beberapa gejala kalau tidak bisa dibilang penyakit yang terdapat pada Regresi linear. Hal tersebut harus kita lewati sebagai syarat nilai peramalan dan juga koefisien determinasi dari regresi tersebut benar-benar valid. 
Dalam kalkulasi suatu persamaan regresi kita bisa menghasilkan nilai peramalan yang berbeda anatara satu dengan yang lainnya. Bukan salah menghitungnya karena memang sudah sedemikian begitu datanya. Ada beberapa penyebab yang menyebabkan dan biasanya adanya outlier. Bisa jadi kesalahan dalam mengumpulkan data juga turut serta dalam menghasilkan peramalan yang salah. Sudah nilai tersebut salah maka salah karenanya asumsi inilah yang harus diperbaiki. 
Ada beberapa hal yang membuat regresi tersebut tidak akan menjadi valid yang bisa kita perhatikan seperti ini: 

## Multikolinearitas. 
Kita mau mencari hubungan anatara variabel independen dengan variabel yang dependen, hanya saja terjadi hubungan yang baik antara variabel independen dengan variabel independen juga atau sesama variabel independen. Hubungan ini tidak bisa dibiarkan karena akan menyebabkan variabel tersebut merusak nilai perhitungan dari regresi.
Hubungan sesama variabel independen dapat menyebabkan nilai R begitu tinggi, namun penduga (peramalannya menjadi bias). Untuk itu hal ini harus diatasi dengan cara membuang salah satu variabel yang sama. 
Sebenarnya tidak terlalu sulit untuk menduga akan terjadinya multikolinearitas . Ketika kita melihat ada data tabel yang begitu mirip antara sesama variabel independen, kita harus mengecek apakah kita menyalin data yang sama untuk variabel yang berbeda. Terkadang salah satu data merupakan kelipatan dari data yang lainnya dan inilah yang menyebabkan korelasi begitu tinggi. Pastikan juga tidak ada data yang sama masuk ke dalam variable yang berbeda. Jika yakin ternyata data tersebut juga memang benar maka bisa jadi itu data memang mempunyai sifat yang sama. Hubungan antara korelasi keduanya sangat besar sekali hampir sampai lebih dari 80%. Kalau kita menggunakan Korelasi Pearson maka kita akan mendapatkan nilai korelasi yang tinggi.  
Kesalahan ini bisa jadi karena memang datanya seperti itu. Seperti harga ayam kampung dengan harga ayam ras maka kita bisa pastikan keduanya mempunyai hubungan yang positif. Kalau harga ayam ras naik maka harga ayam kampung juga naik. Meski keduanya mempunyai harga yang berbeda namun mempunyai peluang untuk naik pada waktu yang sama atau turun pada waktu yang sama. 
Untuk mendeteksi dari gejala ini adalah dengan melihat nilai VIF yang ada dalam software statistik. Nilai VIF yang lebih besar dari 10 maka terjadi yang namanya multikolinearitas.  Kemudian ada juga nilai eugin value yang lebih dari 0,001. 
Untuk mengatasi multikolinearitas adalah tidak sulit. Hanya saja pilihannya adalah membuang salah satu variable dalam regresi multi variable. Hanya saja masalahnya adalah pilihan yang mana yang mau dibuang kadang ini menjadi pilihan yang dilematis. 

```{r}
library(car)
library(carData)
vif(regresimtcars1)
```
HAsil dari regresi tersebut menunjukan tidak terjadinya apa yang namanya multiklineartiast karena nilainya adalah 5,366629 atau masih dibawah nilai VIF=10 

## Autokorelasi 

Nilai Autokorelasi terjadi ketika deret waktu mempunyai nilai galat (error)  yang berkorelasi .Hal ini terjadi karena data berseri (time series) yang ada dalam suatu model. Pada beberapa kasus ternyata data cross section sendiri juga dapat mengalami autokorelasi. Pada autokorelasi terjadi karena galat yang berubah menurut waktu. 

Untuk menilai apakah adanya terjadinya korelasi, kita dapat menggunakan kriteria sebagai berikut yakni dl (Durbin lower) yang berarati nilai Durbin terendah atau  du (Durbin upper) yang berarti nilai durbin di atas. Semua nilai yang berada di antara kedua nilai tersebut harus memenuhi syarat sehingga, model yang kita buat sudah dikatakan terbebas dari autokorelasi. 

Autokorelasi adalah suatu hubungan galat atau error yang berhubungan. Hubungan tersebut akan semakin membesar dan semakin mengecil pada tingkat peramalan yang dibuat oleh model yang memiliki gejala autokorelasi. Mau tidak mau nilai dari autokorelasi harus dihilangkan terlebih dahulu. Dengan kata lain kita harus membuat sesuatu model yang terbebas dari autokorelasi. Apapun regresi yang terjadi kesalahan termasuk autokrelasi karena adanya data tersebut. Karenanya pastikan terlebih dahulu data yang anda kumpulkan tersebut memang sudah benar. Setelah yakin kalau sudah melakukan regresi lagi. 

Untuk mendeteksi gejala ini kita mengamati pola residual terhadap urutannya atau t. Kalau data residual mempunyai pola tertentu baik meningkat maupun menurun maka patut dicurigai terjadinya autokorelasi. Kalau data tidak mempunyai pola **(pattern)** atau data tersebar dengan bebas maka tidak terjadi autokorelasi. 

Selain melakukan uji Durbin Watson kita bisa melakukan uji yang lain seperti Ljung Box  uji ini juga dapat untuk menduga regresi yang kita lakukan. Uji ini akan menempatkan H0 atau Hipotesis nol adalah hasil regresi terdapat mengandung autokorelasi sedangkan hipotesis alternatif (Ha) menunjukkan kalau tidak ada autokorelasi dalam model yang diuji. 

Nilai Durbin Watson yang dikembangkan mempunyai rumus seperti di bawah ini \@ref(eq:durbin)


\begin{equation}
du=  (∑_(t=1)^n(e_(t-1)-e_t )^2 )/(e_t^2 )
(\#eq:durbin)
\end{equation}


Dengan et = nilai error ke t 
              et-1  = nilai error ke t-1 

Dalam uji ini ditetapkan sebagai Hipotesis nol adalah jika terjadi autokorelasi sedangkan Ha diterima jika terjadi autokorelasi 

H0 : ρ = 0 tidak terjadi autokrelasi 
Ha : ρ ≠ 0 terjadi autokorelasi

Autokorelasi itu terjadi karena danya kandungan data series tetapi seperti disinggung diatas kalau data cross section pun juga menjadi autokorelasi untuk mengatasi adalah kita bisa melakukan hal seperti ini. Kita menggunakan differencing pada data time series. Setelah difference atau pembedaan ada kemungkinan data time series juga bisa diperbaiki. 

Salah satu mengatasi dengan menggunakan lag. Lag ini adalah konsekuensi dengan nilai dari regresi tersebut. Ada beberapa variable respon tidak selalu merespon dengan cepat. Karenanya ada sebuah respon tersebut maka aka nada repson yang terlambat sekali . Adapun bentuk antisipasi memang semuanya bervariasi karena memang tidak langsung. Bahkan kita curiga kalau suatu reaksi sudah diketahui sebelumnya berarti ada efek antisipasi oleh respon tersebut. 

Untuk memeriksa apakah adanya autokorelasi maka kita bisa melakukan hal seperti ini yakni menggunakan dwtest yang ada di package lmtest;
```{r}
library(lmtest)
dwtest(regresimtcars1)
```
kemudian jalankan dwtets hasilnya menunjukkan nilainya tdiak signifikan berarti menerima hipotesis nol yang menunjukkan tidak terjadinya autokorelasi 




## Heteroskedatisitas

Pada mengumpulkan data,  kita mungkin kurang memperhatikan adanya variance yang berbeda. Seharusnya dalam peramalan regresi juga kita harus memperhatikan asumsi bahwa error tidak berbeda E( ε ) = 0. Adanya perbedaan karena memang sulit sekali bagi regresi linear untuk mencari nilai yang paling mendekati dengan garis persamaan regresi yang mendekati dari data tersebut. 

Hal ini harus segera dipebaiki. Sebelum kita melihat adanya dugaan heteroskedatisitas kita harus melihat terlebih dahulu adanya potensi dari heteroskedatisitas. Kita tahu adanya variance yang berbeda antara Y prediksi. Tentu untuk meminimalkan kita bisa menghilangkan hal tersebut. Penyebab dari terjadinya heteroskeditas adalah nilai yang ekstrim atau outlier dalam data. Maka data outlier tersebut jauh dari peramalan sedangkan kita sulit untuk membuat ramalan yang tepat. 
Dalam hal ini kitameyakini tidak adanya heterosekdatistiasta dalam model ini menggunakan uji studentdized Breusch-Pagan Test. Dalam uji ini RStudio akan mengelola nilai galat tersebut. DAri uji maka 

Ho ; Tidak Terjadi Hteroskedatisitas 
H1 : Terjadi Heteroskedatitisitas 

Kalau nilai peluang (p-value) > dari 0,005 maka kita akan menerima HO 

```{r}
library(lmtest)
bptest(regresimtcars1)
```

Di awal mungkin kita tidak bisa untuk menebak atau menduga apakah yang terjadi dalam regresi kita tetapi kita bisa lakukan antara lain 

Plot scatter antara predictor value dan residual kalau memuat grafik seperti pola topi runcing atau cone, maka akan adanya heteroskedatisitas 
	
Plot scatter antara nilai yang diprediksi dan residual kalau berbentuk seperti pola tertentu bisa jadi pola sebaran itu seperti ada garis yang mempunyai trend cenderung ke atas atau ke bawah. Ada sekumpulan garis residual yang membentuk suatu pola. Tentu hal ini tidak baik karena menunjukkan adanya pola tertentu. kita bisa melakukan seperti mmembuat plot dari taksiran dan juga residual @Marliana2017.
	
Breusch pagan dan white test adalah untuk mendeteksi adanya heterosskedatisitas dengan cara menghitung. BReusch Pagan akan menghitung nilai \@ref(eq:BP)
	
\begin{equation}
BR=  n.R^2
(\#eq:BP)
\end{equation}	

Setelah kita mengetahui adanya gejala heteroskedatisitas maka kita harus memperbaiki hal tersebut. Ada beberapa hal namun sebelum kita memperbaiki kita harus melihat dulu mengapa terjadi heteroskedatistas 

```{r}
residuals(regresimtcars1)
taksiran<-fitted(regresimtcars1)
kresid=residuals(regresimtcars1)*residuals(regresimtcars1)
plot(taksiran,kresid)

```


Hetereoskedatisitas mengakibatkan peramalan menjdi bias membuat estimasi tidak efisien. Dalam regresi heteroskedatisitas mengakibatkan nilai t akan besar sehingga seolah terlihat nilai yang sangat signifikan. Nilai tersebut tentu tidak baik dan tidak mencerminkan nilai yang sesungguhnya. Supranto





### Ibarat memperbaiki Kursi {-}
Ketika kita memperbaiki suatau gejala contoh autokorelasi bisa jadi heteroskedatisitas yang tadinya belum ada akan muncul. Hal ini bisa terjadi kalau perbaikan pada kita seperti kita memukul kayu di suatu tempat maka akan ada yang terpukul di lain pihak hal itu biasa saja dalam praktik untuk membuat suatu model yang tepat . Maunya kita membetulkan satu namun tidak merusak yang lain tapi itu tidak bisa terjadi. Kalau kita mengetahui akar masalahnya maka kita akan bisa menyelesaikan masalahnya.

Terkadang beberapa hal yang banyak yang sudah kita laakukan namun belum memasukkan atau belum menemukan suatu model yang sudah terbebas dari keseluruhan asumsi normal yang menjadi syarat dalam regresi sudah terbebas. Baru model tersebut dapat dikatakan menjadi estimator atau penduga yang baik. 

Untuk itu memang perlu kesabaran dari proses pengolahan data tersebut. Karena adalah hal yang ketentuan bisa menjadi berubah maka hal itu harus melewati revisi juga. 


Regresi linier sederhana	Regresi linier bergabda
Asumsi Normal 	V	V
Multikolinearitas 	X	V
Heteroskedatiositas	V	V
Autokorelasi	V	V


## Asumsi Normalitas 
Kembali lagi ke dalam stataistik dasar kalau kita tahu bahwa regresi tersebut juga memiliki data yang normal atau normalitas. Nilai residual dari peramalan tersebut terdistribusi normal. Jadi bukan datanya yang terdistribusi normal. Ketika hasil regresi linier berganda ini adalah kita akan melihat nilai residual adalah normal atau terdistribusi normal. Data yang normal adalah data yang tersebar menurut seperti lonceng tersebut. Data yang tidak tersebar normal berarti ada sesuatu yang tidak sesuai. Karenannya hasil prediksi dari data tidak normal menjadi tidak konssten. 

Untuk membuktikan kalau sebuah hasil residual terdistribusi normal maka kita bisa melihat dari table satu grafik batang yang menunjukkan sebaran yang normal. Sebaran normal seperti bentuk gunung yang simetris atau lonceng yang simetris. Baik sisi Kanan dan kiri mempunyai dua  sisi yang terbagi sempurna. Kalau sudah seperti ini mska data akn tersebar normal. Pada dasarnya kita sulit sekali mendapatkan sesuatu ynag normal. Terkadang dan memang seringnya muncul grafik yang tidak normal. Hal ini biasa saja karena persebaran data tersebut sering tidak normal apalagi kalau menggunakan data yang dalam jumlah terbaras. Ada kemungkinan data akan mempunyai banyak outlier yang akan menyebabkan residual malah tidak baik model permalannya

KIta menggunakan uji Shapiro test akan seperti ini adalah
Dalam melakukan uji regresi kita harus memastikan kalau data tersebut juga harus mempunyai normal.Data yang tersebar normal ini penting untuk memastikan kalau hasil regresi tersebut menjadi sah. Untuk melakukan itu kita bisa melalukan uji baik dengan test Shapiro-Wilk Normality Test atau kita juga menggunakan qqnorm atau qqline dari reisudal tersebut. 

Melakukan uji normalitas pada data dengan Shapiro Wilk test adalah dengan mengetikan perintah shapiro.test terhadap residual regresi mt cars. Dari sana terlihat output tersebut

```{r}
shapiro.test(residuals(regresimtcars1))
```
Kita juga dapat melihat dengan plot ini untuk meyakinkan kalau data tersebar normal. Hasil nilai dari Shapiro adalah 0,9419. Dalam uji ini Nilai Ho adalah Data tersebar normal sedangkan Hipotesis Alternatif (Ha) dari uji ini adalah data tdiak tersebar normal. Aturan dalam uji ini jika nilai p (P-Value) ebih besar dari 0,05 (p>0,05) maka keputusan dari uji ini dalah tidak bisa menolak HO. Artinya Data pada reiduals ini adalah tersebar dengan normal.
 
Selain itu kita bisa melakukan dengan grafil normal qq plot. Dengan data itu kita bisa untuk melihat adanya data yang tersebar normal. Kita bisa menggunakan perintah qq normal dengan residuas. Kemudian kita bisa menambahkan qqline. Agar terlihat garis data normalitasnya. 
 

```{r}
qqnorm(residuals(regresimtcars1))
qqline(residuals(regresimtcars1))

```




# Regresi Logistik 
Dalam regresi logisitik kita akan membuat sesuatu  variabel logistik atau logit yang berbeda dengan regresi linear . Hal ini berbeda karena regresi linear biasa menggunakan variabel rasio. Untuk regreesi logistik kita dapat memberikan variabel indepnden antara 0 atau 1. Pemilihan variabel independen ini hanya dua saja biner atau (binary), misalnya antara laki dan perempuan, sakit dan sehat, sejahtera dan non sejahtera dan lain-lain. Adapun untuk variabel dependen maka hal itu dibolehkan berupa data rasio Terkadang ada juga data yang menggunakan data yang lain juga. Hal ini bergantung dengan kebutuhan penelitian yang ada. Tetapi pada beberapa kasus bisa jadi regresi yang dilakukan adalah regresi kategorik juga.
Kita bisa mengembangkan model dari variabel independen yang akan kita cari prediksinya dengan beberapa faktor independen yang diduga dapat untuk mempengaruhi dari nilai variabel Y tersebut. Hal itu bisa kita lihat dalam studi mengenai regresi logistik tersebut yang ada di jurnal. Kita sambungkan teori dengan penerapan regresi logistik.  
Regresi logistic sebagai reposn dari keterbatasan regresi linear. Ada nilai yang sebagai variabol explanatory yang berkisar anatara pilihan nilai 1 dan juga nilai 0 saja. @Wooldridge2012

## Contoh Regresi Logistik dalam Rstudio

Untuk melakukan hal ini kita menggunakan dataset dari mtcars . kita menjadikan variabel am atau automatic machien 1 untuk nilai automatic sedangankan ) untuk nilai non automotaic. dari sini kita melihat bahwa peluang **probabilitynya** adalah kalau nilai variabel independennya am satu adalah dipengaruhi dengan nilai wt yang seara signifikan. Maka jdul berat adalah mempengaruhi terhadap mesin. sedangankan mpg atau jumlah minyak per gallon (mill per gallon) adalah tidak berpengaruh signifikan pada probabailitas dari nilai mesin automatik. 

```{r}
modellogitcar <- glm(am ~ mpg + wt + hp, data = mtcars, family = binomial)
summary(modellogitcar)
```
### Uji Asumsi model{-}

Setelah kita melakukan regresi maka kita bisa menguji asumsi model yakni beberapa model dengan uji multikolinearitas seperti kita harus mempunyai package car. kalau belum punya maka kita harus menginstall terlebih dahulu library (car). ada beberapa tahapan lagi yang bisa kita untk menguji seperti yang ada di artikel @Alice2015
```{r}
library(car)
vif(modellogitcar)
```

Hasil menunjukkan nilai dari vif terlalu besar untuk variabel mpg dan Hp yakni 15,54 dan juga nilai untuk VIF hp adalah 18.073863 maka dengan demikian kita akan berkihtirar dengan menghilangkan nilai mpg atau nilai hp di contoh bawah akan saya hilangkan sehingga mmepunyai persamaan yang baru. 

```{r}
modellogitcar2 <- glm(am ~ mpg + wt, data = mtcars, family = binomial)
summary(modellogitcar2)
vif(modellogitcar2)
```

Nilai dari vif sudah berkurang menjadi 3,556491 baik mpg maupun wt. maka dengab pengurangan variabel hp dapat untuk menurunkan hubungan atau korelasi anatara variabel mpg dengan hp tersebut. 

Selanjutanya adalah kita akan melanjutkan dengan berbagai asumsi yang lain. 

## Bagaimana interprestasi model ? 
Hasil regresi menghasilkan beberapa nilai yang perlu dianalisis . Nilai-nilai tersebut sama-sama seputar regresi namun karena adanya nilai dikotomi maka kita ajan sedikit berbeda untuk Apakah kita akan membedakan analisis dua data kategori tersebutnya. Tentu hal itu akan dibicarakan dan akan dijelaskan dari nilai dikotomi tersebut. Misalnya untuk regresi yang nilai angka 1 dan angka 0 maka kita harus memperhatikan kedua dikotomi tersebut. Ada hal yang membedakan karena dari awalnya memang untuk melihat pengaruh antara dua variabel kategori tersebut. 
Mungkinkah dari hal tersebut kita bisa memberikan interprestasi yang berbeda? Pada hubungan antara variable dependen dengan variable independen maka kita melihat nilai dari signifikasi dari hubungan atau relasi antara variable dependen dengan variabel independennya. Kita melihat nilai p value atau Probability value. Seperti sudah menjadi kebiasaaan kalau nilai pvalue tidak boleh lebih dari 0,05 atau 5%, 
Kemudian melihat table ANOVA apakah nilai model sudah sesuai dengan harapan. Nilai ini menghitung kalkulasi perbedaan antara variabel dependenden maupun variabel independen. Hipotesis nol adalah tidak terjadi perbedaan yang artinya seluruh rata-rata dari nilai akan menjadi sama. Sedangkan pada hipotesis alternatif atau Ha adalah setidaknya ada satu variabel yang memiliki nilai yang berbeda. 
Adapun persamaan dari nilai logisitik adalah seperti ini @\ref(eq:logistic) 

\begin{equation}
P(Y = 1 \mid X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_k X_k)}}
(\#eq:logistic)
\end{equation}

$$
\begin{align*}
\text{Keterangan:} \\
P(Y = 1 \mid X) & : \text{Probabilitas bahwa variabel dependen } Y \text{ bernilai 1, diberikan nilai } X. \\
\beta_0 & : \text{Intercept (konstanta), yaitu log odds ketika semua } X_j = 0. \\
\beta_1, \beta_2, \ldots, \beta_k & : \text{Koefisien regresi untuk masing-masing variabel independen.} \\
X_1, X_2, \ldots, X_k & : \text{Variabel independen (prediktor).} \\
e & : \text{Basis logaritma natural, dengan nilai mendekati } 2.718. \\
z & = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_k X_k : \text{Kombinasi linear dari model.} \\
\end{align*}
$$

Pada bagian variabel independen atau juga variabel bebas aka ada nilai p/(1-p) maka hal itu adalah perbandingan anatara variabel dikotomi dalam variabel independen tersebut. Misalnya kita menetapkan p itu sebagai sukses maka nilai (1-p) adalah nilai non sukses atau gagal. Contoh juka demikian kita dapat menulis kemungkinan sukses atas kemungkinan gagal. Kalau kita tetapkan kemumgkinan sukses tersebut adalah 0,7 maka kita bisa masukkan nilai sebagai berikut 0,7/(1-0,7)= 0,7/0,3 = 2,33 . hal ini berarti kita bisa artikan kalau nilai kesuksesan mempunyai peluang 2,33 kali lebih banyak daripada kegagalan. Begitu juga nilai tersebut kita bisa gunakan yang lain untuk memasukkan nilai p sebagai nilai untuk satu peluang yang sudah saya tunjuk. Perbandingan rasio antara sukses dan tidak sukses disebut juga odds. 

Persamaan logistik

Dalam regresi logistik tidak perlu lagi untuk melakukan ujian asumsi klasik seperti yang dialkukan pada regresi linear lainnya. Hal ini mungkin dikarenakan karena sifat nilainya yang sederhana sehingga berbeda. Variabel dikotomi yang lebih sederhana membuat erro mungkin tidak seberapa besar dengan regresi linear. 
Meski tidak menggunakan model asumsi linear akan tetapi ita tetap saja memerlukan untuk menggunakan nilai chi Square. Hal ini penting juga untuk menilaid ari regresi tersebut. Hal ini cukup sebagai tujuam uuntuk mendapatkan nilai regresi tersebut. 
Untuk langkah-langkah dalam regresi logistik ini kita bisa lakukan sebagai berikut : 
1.	Mengumpulkan data menegnai variabel bebas maupun variabel tidak bebas dan mendapatkan seluruhnya ke dalam suatau tabulasi yang baik. Yakinkan data sudah terhitung dengan benar sesuai dengan yang hendak kita carikan. 
2.	Melakukan regresi logistik menggunakan software yang sudah digunakan sebelumnya. Saya memilih menggunakan R karena lebih mudah. 
3.	Memastkam nilai dari regresi itu sesuai dengan yang kita iningnkan. Nilai dari regresi terlepas dari beberapa hal seperti nlai Chi square
4.	Menginterprestasikan nilai dari regresi logistik dari perhitungan probabilitas dari hasil software.

Interprestasi dari hasil regresi logistik 
Ketika kita sudah mendpatkan hasil regresi maka kita harus tahu untuk menerjemahkan hal ini. Dalam regresi logisitik tidak seperti regresi persamaan yang bentuknya linear. Kalau dalam regresi linear variabel bebas dapat memepengaruhi dalam besaran sekian berkat dari nilai koefisien yang ada dalam persamaan tersebut. 
Tetapi karena ada dua dari jenis dari variabel independen. Maksudnya ada dua kemungkinan binary atau dua peluang ketika seorang untuk memeilih nilai satu atau dua saja. Mudah seperti itu maka interprestasinya dalah seperti ini. Kalau saya mencontohkan dengan anak yang luslu maka anak yang lulus harus mempunyai syarat seperti nilai ujian yang bagus, kehadiran yang menutupi yang lain. 
Ketika itu kita dapat memilih peluang dari anak yang akan khusus dari nilai ujian Mata Kuliah Ujian tertentu harus memenuhi beberapa hal.
Untuk yang sederhana saja kita bisa mencari hubungan perokok dengan usia yang ada. Apakah kita hubungkan anatar usia sebagai varabel bebas berhubungan dengan variabel yang kita cari. Tentu kita masih memetingkan apakah nilai signifikan dari variabel tersebut karena kalau tidak signifikan maka kita tidak bisa untuk memprediksi dari nilai tersebut. 
Misalnya saya akan meprediksi nilai kebangrkutan dari persauaahn dengan nilai seperti ini:
Log(p/(1-p) = b0 + b1*ROA 
Nilai p adaah nilai peluang perusahaan mengalami kesulitan keuangan, b0 adalah nilai konstanta dan b1 adalah nilai koefiseien dari variabel bebasnya, dalam hal ini variabel bebasnya adalah **Return on Assets (ROA)**.
Untuk kta melakukan interprestasi adalah  seperti dibawah ini . Nilai intercept atau kosntanta adalah nilai yang masih ada ketika nilai ROA menjadi nol. Apakah mungkin nilia tersebut atau nilai ROA itu bisa nol. INi mungkin saja karena ada perusahaan yang tidak menghasilkan nilai keutnungan atau nilainya menjadi nol sehingga pendapatan dari perusahaan tersebut adalah nol. Kemudian adalah nilai koefisein dari ROA ini adalah seebrapa besar pengaruh jadi bukan menunjukkan kuatnya hubungan melainkan nilai besaran yang mempengaruhi rasio logit tersebut. 
Tentu menerjemahkan dari persamaan itu butuh berupa hasil. Katakanlah jika kemungkinan dari financial distress itu hanya 0,1 maka peluang maka ada kemungkinan kebangkrutan itu hanya sekitar 0,11 kali karena dari nilai 0,1/0,9 maka akan ada nilai yang besar sekali. 

(kutipan) Dalam regresi logisitik ada berapa asumsi yang bisa kita penuhi antara lain: 
1.	Error harus berdistribusi normal 
2.	Heterosedatisitas 
3.	Hubungan variable bebas dan tidak bebas yang ternyata tidak linear

Pertanyaan 
1.	Apa Perbedaan Regresi Liniear dan Regresi Logistik?
2.	Apa definsi dari regresi logistic? 
3.	Apa tahapan dalam regresi logistic?
4.	Setelah mendapatkan nilai regresi logsitik maka bagaiaman kita meyakinkan kalau nilai hasil regresi kita sudah terbebas dari asumsi yang buruk?
5.	Apa saja yang bisa kita tafsirkan jika kita mendapatkan hasil regresi demikian
6.	Bagiaman cara memprediksi probabilitas kejadian dari model regresi logisitik ?
7.	Jelaskan bagaiman menetapkan nilai 1 dan 0 pada variable independn tersebut?
8.	Bagiaman penerapan regresi logsitik dari bidang manajemen ?
9.	Apa yang dimaksud odds ratio dan mengapa itu penting?
10.	Bagiaman cara pemilihan variable dalam regresi logistic? 

# Regresi Dengan Data Kategori (Dummy)

Regresi dummy 
Kalai kota menetapkan Y sebagai variabel kategoriknitu berarti kita melakukan regresi logistik atau logit. Hanya saja ada yang masuk dalam variabel kategorik yang bisa kita gunakan untk menyelidiki hubungan kategorik dengan varoabel tertentu. Dalam regresi linear menggunakan data kategori sebagai variable independent dengan menamakan huruf satu dengan variable tertentu dan angka 0 untuk variable lainnya. 
Contoh perempuan yang cenderung rajin daripada laki-laki akan menghasilkan nilai yang lebih baik dari laki-laki. Tentu kasus per kasus akan berbeda dengan yang lainnya karena bisa jadi di beberapa bagian lelaki akan ada yang mempunyai prestasi lebih baik. Off course, kita bukan bicara mwngenai hal itu karena Statistik itu akan bicara banyak sample yang mewakili.

Variabel kategori atau disebut dummy ini memang akan membuat sesuatu yang berbeda dengan variable yang lainnya. VAriabel ini bukan masuk dalam variable angka atau kuantitaif melainkan ini adalah variable 
Hal itu karena antara dua kategori itu ada hal yang berbeda seperti laki-laki dan perempuan. Pemaksaan untjk mencari nilai akan membuat sesuatu menjadi terpaksa dan akan terjadi nilia residual yang sangat besar sekali dan patutu diduga model regresi akan bias tidak memenuhi BLUE.
Adanya aktegori ini sedikitnya melonggarkan .dalam satu persamaan ada aetidkanya dua kategori kalau dalam satu variabel. Maka kita akan membedakan anatara laki-laki dan perempuan. Untuk memudahkan maka si peneliti akan memberikan angka 0 untuk perempuan dan angka 1 untuk laki-laki. Seperti habg kita sudaj bahasa sebelumnya jika nilai peramalan atau corecast dari perempuan hanya berupa Beta Sajam karena nilai 0 akan menihilkan angka X maupun nilai Beta yang ada dalam persamaan. Sedangkan untuk nilai laki-laki akan mendapatkan tambahan dari Beta selain nilai dari alpha tentunya.

Apakah model Dummy selalau dipakai. Hal itu tentu dengan kebutuhan yang ada. Kalau terajdi perbedaan yang behitu signifikan maka kita akan menggunakan hal seperti itu tetapi kalai kita yka wlihat hal yang penting maka kita pehih baik tidak usah memakai dummy.
Bagaiaman anda membuat model?

Membuat model bagi seorang yang pemula dan peneliti pemula adalah dengan menggunakan model yang sebelumnya. BUkan menyalin adalah sesuatua yang mudah. setidaknya dalam menggunakan model yang sudah ada karena model tersebut sudah terbukti . Kalau belum terbukti atau merancang memang akan sulit sekali dengan demikian. misalnya kita sudah pasti tdak ada perbedaan aanatara kecerdasan wanta dan laki-laki dalam ilmu bahasa maka akan sulit sekali mmenggunakan hal itu untuk membedakan anytara satu dengan yang lainnya. HAl itu menjadi percuma saja kalau kita tidak menemukan hal yang membedakan dalam modle tersebut maka lebih sederhana saja kita tidak usah untuk membuat modle sperti itu. KIat tinggal menggunakan regresi yang sudha biasa diguankan saja yang lebih sederhana maka itu akan lebih baik dan tidak perlu untuk membuat teori yang baru. 
Ketika anda bisa untuk mencari model yang membutuhkan dummy maka anda sebaiknya juga dapat mengikuti hal itu. HAl seperti ini

Ketika sebuah regresi tidak memenuhi syarat kita mungkin bertanya apakah penyebabnya? Padahal kita sudah memenuhi asumsi yang sudah kita penuhi sebelumnya . Kita sudah melakukan perbaiki asumsi yang sudah ditetapkan.
Permasalahan adalah bukan karena datanya. Kita sudah sepakat kalau data adalah netral. Ia seperti halnyaa bahan makanan yang segar tentu saja kalau anda memilih data yabg benar
Data yang salah akan menghasilkan olahan yang salah. Sama seperti telur busuk yang akan menghasilkan kue yang dihasilkan dari telur busuk. Bagaimana rasanya? Pasti rasanya sudah tidak bagus lagi. Hal ini karena sudah buruk.
Dalam membuat suatu model maka kita juga harus memperhatikan model yang sebelumnya sudah ada ini penting juga. Sebaiknya kita sudah mencontoh apa  model apalagi hanya dalam tataran sekolah sarjana saja.

Dengan mencontoh model bukan berarti plagaitor karena model yang sudah ada bisa menjadi rujukan bagi kita untuk menjadikan sebuah penelitian yang akan kita lakukan. Jika seorang peneliti muda maka mereka seharusnya membuat yang mirip saja atau duplikasi saja.

Ketika kita memilih regresi maka kita tahu bahwa akan memeriksa hubungan antara satu faktor dengan faktor yang lainnya. Apakah ada hubungan dengan hubungan yang lain? Karena itu memang ada hubungannya dengan hubungan yang lain. Kalau tidak ada hubujgan dengan yang lain maka kita tidak bisa memeriksakannya. Kalaupun memqksakan visa jadi ada hubungan seperti yabg saya jelaskan namun hubunga tersebut tidak bisa valid.
Salah satu cara meyakini adalah denga literatur. LIteratur tersebut adalah landasan kita untuk membuat 
Kira aka. Membagi beberapa hal yang bisa kita bagikan. Dalam hal ini kita menggunakan variabel dummy atau variabel boneka. Variabel ini menggunakan angka 10 dan 0. Lalu bagaimana penetapannya. Umumnya dua angka ini untuk membedakan. Jangan kita membuat sendiri tanpa adanya pertimbangan yang matang dengan hal itu. Kita harua bisa memberikan pertimbangan yang pas bagi model yang kita bangun. Sebab namanya statistik bisa dibuat apa saja.
Setelah itu kita membagi kategori itu. Berapa yang hendak kita gunakan kategori. Kalau kita hanya menggunakan dua kategori maka kita hanya membutuhkan satu data dummy saja. 
Kalau kita mempunyai tiga kategori maka kita setidaknya bisa untuk membuat dua variabel dummy saja. Maka kalau kita mempunyai beberapa kategori kita akan membuat dengan banyaknya kategori dikurangi satu atau variabel atau 

banyaknya variabel dummy = kategori - 1 

Maka kita juga ahrus bijak dalam menggunakan variabel dummy tersebut karenan banyaknya akan kemungkinan membuat asusmi regresi bisa menjadi tidak terpenuhi terutama adalah masalah multikolinearitas. Maka kita harus membuatnya sesuai dengan kndis dan pemenuhan data. yang ada . 

Misalnya kita ingin membuat kategori pendidikan dari tiga tingkatan stratat yakni kategori bawah sarhjana , kategori sarjana , dan kategori di atas sarjana maka akan duibuat dua dummy variabel. yakni 

Y= a + b1.X1 + b2.D1.X + b3.D2.X + e 

kategori satu akan saya masukkan untuk sarhana sedangkan kategori dua adalah master maka yang bukan sarjana akan masuk dalam kategori tersebut. HAsilnya kita akan bsia melihat bahwa dnegan adanya data dummy tersebut maka saya bisa memprediksi ada perbedaan anatara beberapa kategori tersebut.
```{r}
#Regresi Data mytcars dengan variabel dummy
mtcars
library(lmtest)
library(zoo)
#Kita regresi dengan data nominal atau dummy
#mengecek apakah ini variabel kategori
is.factor(mtcars$vs)
#mengecek jenis atau kelas dari data
class(mtcars$vs)
#mengecek tipe variabel
str(mtcars$vs)
#untuk mengecek semua data bisa kita lakukan seperti ini
sapply(mtcars,class)
#atau
sapply(mtcars,is.factor)
#saya merubah faktor ke dalam bentuk kategorik (dummy)
mtcars$vs <- factor(mtcars$vs, levels = c(0, 1), labels = c("0", "1"))
library(car)
modeldummy<-lm(log(mpg)~wt+vs+disp,data=mtcars)
summary(modeldummy)
library(ggplot2)
vif(modeldummy3)
dwtest(modeldummy)
bptest(modeldummy)

```


# Regresi Non Linear

Ada bebebrapa hal yang tidak di wakili oleh regresi linear. Ketika regresi linear yang sudah kita pelajari adalah menggambarkan suatau hubungan yang dalam bentuk garis lurus atau linear. Kini dengan adanya non linear maka hal itu masih menjadi kompleks lagi dengan hubungan yang bukan linear atau non linear. Hubungan dalam grafik antara regresi non linear akan berbeda dan bukan lagi digambarkan sebagai garis lurus akan tetapi sebagai garis yang tidak lurus. Regresi adalah salah satu bentuk Akomodasi dari hubungan linier yang tidak bisa diwakili oleh regresi linear @James2023

Dalam regresi kuadratik kita dihadapi dengan nilai yang berhubungan tidak bisa liner. Umumnya kudaratik membuat gerakan seperti gerakan parabola yang akan sulit dibaca dengan menggunakan garis yang linier. Memang apakah linier itu selalu hebat? ini menjadi pertanyaan sendiri. Jarang sekali model yang bentuknya kudrat dan itu memang yang sering terjadi karena memang hubungan itu mungkin hampir setara. Mungkin banyak orang yang berpikir kalau kuadrat itu memang tidak umum. Apalagi kalau sudah variable lebih dari satu, hubungan tu akan seperti pencaran yang berbeda-beda. 
Ada pola-pola hubungan yang tidak bisa digambarkan dengan regresi non linear sehingga tidak menghasilkan regresi linier seperti polynom, logaritmik dan eksponensial. Kalau anda bisa melihat maka anda akan lihat hubungan garis ini tidak normal. 
Untuk mencari adanya hubungan yang tidak linier kita dapat untuk membuat scatter diagram atau diagram pencar. Ini mungkin tidak 
Sehariusnya atau awalnya garis dalam hubungan variabel tersbeut lurus namun ternyata tidak lurus. Tentu, tidak semua hubungan akan selalau linear dan juga bukan berarti seluruh hubungan juga non linear. Kita melihat atau mendeteksi dari perubahan apakah ada data yang terlihat berubah secara drastic?
Zaman telah berubah karena begitu pesat sekali tekhnologi dnengan nama yang awalnya mesin penghitung (computer) ada yang namanya perhitungan dengan model sederhana namun kini perhitungan tersebut sudah lebih canggih lagi dari keadaan masa lampau.

Kalau sekarang begitu banyak software stataistik yang dapat menghitung banyak dengan cepat. karenanya dengan ilmu yang modern tersebut maka bisa untuk mencari hal yang baru dengan perhitungan yang akurat. 

Awalnya mungkin kita akan kesulitan untuk menentukan apakah akan terjadi regresi linear atau tidak. 

## Mendeteksi awal
 
Ketika kita ingin menduga suatau hubungan kita dapata melihat pola hubungan variable bebas terhadap variable tidak bebas atau dependent. Kita akan membuat suatau diagram ppencar yang menunjukkan hubungan antara kedua variable tersebut. 

Kalau kita melihat dari dataset trees maka kita bisa lanjutakan seperti ini \@ref(fig:scatter-fig2)

```{r scatter-fig2, fig.cap='Diagram Scatter!', out.width='80%', fig.asp=.75, fig.align='center', fig.alt='Scatter Diagram data trees.'}
plot(trees$Girth, trees$Volume, 
     main = "Scatter Plot of Volume vs Girth",
     xlab = "Girth",
     ylab = "Volume",
     col = "blue",
     pch = 19) # Bentuk titik
```


Dibawah ini adalah contoh regresi non linear dalam bentuk kurva kuadrat dengan seperti dibawah ini. 


```{r}
#Regresi Quadratic 
data(trees)
model_quadratic <- lm(Volume ~ Girth + I(Girth^2), data = trees)
summary(model_quadratic)
```

Dalam contoh ini kita menggunakan regresi kuadratik atau pangkat dua untuk menduga pertumbuhan dari pohon. Kita menggunakan dataset trees yang ada di Rstudio. KIta akan mencoba dengabn persamaan Voolume sebagai variabel dependen atau terikat dengan variabel independen Grith. Maka kita bisa mmebuat dengan variabel Grith dalam bentuk kuadrat.

Maka dari persamaan regresi yang kita akan menginterprestasikan dari nilai regresi. yakni adalah 

Volume = 10, 78267 - 2,02914 Girth + 0,254 54Girth^2 
 Dari Persamaan tersebut kita bisa menduga kaau hubungan dengan Girth adalah negatif namun tidak signifikan. sedangkan 
 
